{"meta":{"title":"tiangao","subtitle":"天高云淡","description":null,"author":"stiangao","url":"http://j2go.github.io"},"pages":[{"title":"categories","date":"2017-08-29T16:08:57.000Z","updated":"2021-09-05T08:35:11.973Z","comments":false,"path":"categories/index.html","permalink":"http://j2go.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-08-29T16:08:08.000Z","updated":"2021-09-05T08:35:11.973Z","comments":false,"path":"tags/index.html","permalink":"http://j2go.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Mac 使用教程 - Java开发者视角","slug":"2021-09-05-mac-guide","date":"2021-09-04T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2021/09/04/2021-09-05-mac-guide/","link":"","permalink":"http://j2go.github.io/2021/09/04/2021-09-05-mac-guide/","excerpt":"","text":"Windows 用户Mac 不分区，一般只有一个盘，Command 键大多数时候等于 Ctrl复制逻辑有点不一样，不能像 windows 下先复制再粘贴，而是要复制之后直接拖入下一个文件夹要不然就在终端用 cp 命令，Mac 下终端还是用得比较多的 Linux 用户homebrew ≈ yum ≈ apt-get ≈ pacman常用 shell 命令差不多，bash 脚本一般都可以直接跑，有些命令有细微差别比如看当前文件夹下一层目录的使用容量统计 Mac 下 du -d 1 -h . Centos du --max-depth=1 -h . 文件夹操作在 Finder 中 Command + 上 可以进入当前目录的父目录把 文件夹 直接拖到 终端 里就是该 文件夹路径在终端里使用 open 命令可以用 Finder 打开文件夹 常用快捷键 Command + C：复制 Command + V：粘贴 Command + A ：全选 Command + Shift + 3：全屏截图（+ 4 是选择截图），自动保存到桌面 Command + Z：撤销Command + H：隐藏当前的窗口 Command + Q：退出应用，等于window 下的 Alt+F4 Command + W：退出当前 Tab，浏览器里用得多 Command + T：创建新 Tab Command + N：创建新窗口 Command + 1/2/3/4: 快速切换标签页，浏览器里试试就知道作用了 Ctrl + 1/2/3/4/5: 多桌面的时候可以快速切换桌面 Command + Tab：切换应用 Command + Option + Esc：可以强制退出应用 Control+Command+Q：快捷锁定电脑屏幕 Command+Space（空格键）：搜索，输入简拼可以快速切换应用 Ctrl 在控制台里使用比较频繁，可以使用系统设置交换 Ctrl 和 CapsLock 的位置 修饰键 终端快捷操作 Ctrl + u : 删除当前光标之前的所有字符 Ctrl + k : 删除当前光标之后的所有字符 Ctrl + f : 向前移动光标 Ctrl + b : 向后移动光标 Ctrl + d : 删除光标后一个字符 Ctrl + h : 删除光标前一个字符 Ctrl + e : 移动光标到最后 Ctrl + a : 移动光标到最前 Ctrl + j : 回车（就是回车键的作用,可以减少右手移动次数） Ctrl + L : 清屏 Ctrl + p : 调出命令历史中的前一条（Previous）命令，相当于通常的上箭头 Ctrl + n : 调出命令历史中的下一条（Next）命令，相当于通常的上箭头 Ctrl + r : 根据用户输入查找相关历史命令（reverse-i-search） 常见误区很多人以为 Macos 也像 IOS 一样应用都从 AppStore 下，并不是，直接下软件安装就行了，而且安装过程比 Windows 简单得多，直接把应用拖到 Application 文件夹下即可，卸载的时候直接移到废纸篓 卸载软件 高效工作配置oh-my-zshoh-my-zsh让终端好用到飞起~1sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; HomebrewHomebrew 使用详解，macOS的第二个 AppStore!1/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; Git 常用操作简写配置123456789alias gc=&apos;git checkout&apos;alias gb=&apos;git branch&apos;alias gf=&apos;git fetch&apos;alias gs=&apos;git status&apos;alias gr=&apos;git remote&apos;alias gpl=&apos;git pull&apos;alias gps=&apos;git push&apos;alias gpo=&apos;git push origin&apos;alias gaa=&apos;git add --all&apos; 以上保存到 {user.home}/.zshrc 文件下 Vscode命令行快速编辑项目或者文件 code 搜 idea 可以找到下面这个，可以保持跟 Idea 一致的快捷键 vscode-idea Idea命令行快速打开项目 idea 终端中使用 idea + {文件夹} 可以快速打开项目 必备插件 idea-plugin Alfred or UTools 默认唤起快捷键都是 Option + Space Alfred：系统搜索的增强版，老牌效率神器，macos 体验一半都归功于这个，不过插件好久没新增了 Utools: 国内开发者开发，操作逻辑跟 Alfred 差不多，插件很丰富，功能强大，还能云端同步 Alfred - 一款macOS系统下的效率神器介绍 Mac 效率工具必备神器 —— Alfred utools 支持跨平台，windows linux 都能用，mac 下使用快捷键唤起的时候有一丝的停顿，不如 alfred 流畅","categories":[{"name":"教程","slug":"教程","permalink":"http://j2go.github.io/categories/教程/"}],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://j2go.github.io/tags/Mac/"}]},{"title":"记一道 Java 笔试题","slug":"2017-12-24-java-question1","date":"2017-12-23T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2017/12/23/2017-12-24-java-question1/","link":"","permalink":"http://j2go.github.io/2017/12/23/2017-12-24-java-question1/","excerpt":"","text":"题目100+ 文件，1W+ 单词，设计用 5 个线程统计单词出现次数,输出次数最多的 100 个单词和次数 当时做的很烂，写了快 200 行，一开始的想法是 5 个线程 5 个 map 分开统计，然后归并，最后遍历插入一个 100 大小的有序数组。 后来想想，其实好像有个简单的解法，毕竟这个单词总数又不是很多， 30 行代码就搞定了123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.io.IOException;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;import java.util.List;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.atomic.AtomicInteger;import java.util.stream.Collectors;public class Main &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; String filesDir = args[0]; ExecutorService pool = Executors.newFixedThreadPool(5); Map&lt;String, AtomicInteger&gt; countMap = new ConcurrentHashMap&lt;&gt;(); List&lt;Path&gt; paths = Files.list(Paths.get(filesDir)).filter(path -&gt; path.toFile().isFile()).collect(Collectors.toList()); System.out.println(paths.size()); CountDownLatch countDownLatch = new CountDownLatch(paths.size()); paths.forEach(path -&gt; pool.execute(() -&gt; &#123; try &#123; Files.lines(path).forEach(line -&gt; &#123; String[] words = line.split(\" \"); for (String word : words) &#123; String w = word.trim(); if (!w.isEmpty()) &#123; if (countMap.get(w) == null) &#123; countMap.putIfAbsent(w, new AtomicInteger()); &#125; countMap.get(w).incrementAndGet(); &#125; &#125; &#125;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125;)); countDownLatch.await(); pool.shutdown(); List&lt;Map.Entry&lt;String, AtomicInteger&gt;&gt; top100Wrods = countMap.entrySet().stream() .sorted((a, b) -&gt; b.getValue().get() - a.getValue().get()) .limit(100) .collect(Collectors.toList()); System.out.println(top100Wrods); &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://j2go.github.io/categories/算法/"}],"tags":[{"name":"文件","slug":"文件","permalink":"http://j2go.github.io/tags/文件/"}]},{"title":"Java CSV 文件操作","slug":"2017-10-11-java-csv","date":"2017-10-10T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2017/10/10/2017-10-11-java-csv/","link":"","permalink":"http://j2go.github.io/2017/10/10/2017-10-11-java-csv/","excerpt":"","text":"以前一直以为 csv 就是逗号分隔的表格文件，读取的时候直接每行按逗号 split 之后进行操作，后来发现结果有点不对，列数据里也是会有逗号的！！！甚至还有回车换行符！ CSV 文件定义逗号分隔值（Comma-Separated Values，CSV，有时也称为字符分隔值，因为分隔字符也可以不是逗号），其文件以纯文本形式存储表格数据（数字和文本）。纯文本意味着该文件是一个字符序列，不含必须象二进制数字那样被解读的数据。CSV文件由任意数目的记录组成，记录间以某种换行符分隔；每条记录由字段组成，字段间的分隔符是其它字符或字符串，最常见的是逗号或制表符。通常，所有记录都有完全相同的字段序列。 CSV是一种通用的、相对简单的文件格式，被用户、商业和科学广泛应用。最广泛的应用是在程序之间转移表格数据，而这些程序本身是在不兼容的格式上进行操作的（往往是私有的和/或无规范的格式）。因为大量程序都支持某种CSV变体，至少是作为一种可选择的输入/输出格式。 维基百科：CSV Java 操作库Apache Commons CSV 测试文件123id,name,age01,tom,1202,&quot;t,j&quot;,23 按列读取12345678910111213141516public void readCSV(String file) &#123; try (Reader reader = new FileReader(file)) &#123; Iterable&lt;CSVRecord&gt; records = CSVFormat.DEFAULT.parse(reader); for (CSVRecord record : records) &#123; String column1 = record.get(0); String column2 = record.get(1); String column3 = record.get(2); System.out.println(column1 + \" | \" + column2 + \" | \" + column3); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 测试结果123id | name | age01 | tom | 1202 | t,j | 23 通过 header 读取12345678910111213141516public void readCSVWithHeader(String file) &#123; final String[] header = new String[]&#123;\"id\", \"name\", \"age\"&#125;; try (Reader reader = new FileReader(file)) &#123; Iterable&lt;CSVRecord&gt; records = CSVFormat.RFC4180.withHeader(header).parse(reader); for (CSVRecord record : records) &#123; String id = record.get(\"id\"); String name = record.get(\"name\"); String age = record.get(\"age\"); System.out.println(id + \" | \" + name + \" | \" + age); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 测试结果123id | name | age01 | tom | 1202 | t,j | 23 写 CSV 文件12345678910111213public void writeCSV(String file) &#123; final String[] header = new String[]&#123;\"id\", \"name\", \"age\"&#125;; try (Writer writer = new FileWriter(file)) &#123; CSVPrinter csvPrinter = CSVFormat.RFC4180.withHeader(header).print(writer); csvPrinter.printRecord(1, \"gg\", 14); csvPrinter.printRecord(1, \"p,ff\", 14); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 输出文件内容123id,name,age1,gg,141,&quot;p,ff&quot;,14 疑问CSVFormat.RFC4180 和 CSVFormat.DEFAULT 什么区别？看源代码 1234567891011static &#123; DEFAULT = new CSVFormat(',', Constants.DOUBLE_QUOTE_CHAR, (QuoteMode)null, (Character)null, (Character)null, false, true, \"\\r\\n\", (String)null, (Object[])null, (String[])null, false, false, false, false, false); EXCEL = DEFAULT.withIgnoreEmptyLines(false).withAllowMissingColumnNames(); INFORMIX_UNLOAD = DEFAULT.withDelimiter('|').withEscape('\\\\').withQuote(Constants.DOUBLE_QUOTE_CHAR).withRecordSeparator('\\n'); INFORMIX_UNLOAD_CSV = DEFAULT.withDelimiter(',').withQuote(Constants.DOUBLE_QUOTE_CHAR).withRecordSeparator('\\n'); MYSQL = DEFAULT.withDelimiter('\\t').withEscape('\\\\').withIgnoreEmptyLines(false).withQuote((Character)null).withRecordSeparator('\\n').withNullString(\"\\\\N\").withQuoteMode(QuoteMode.ALL_NON_NULL); POSTGRESQL_CSV = DEFAULT.withDelimiter(',').withEscape(Constants.DOUBLE_QUOTE_CHAR).withIgnoreEmptyLines(false).withQuote(Constants.DOUBLE_QUOTE_CHAR).withRecordSeparator('\\n').withNullString(\"\").withQuoteMode(QuoteMode.ALL_NON_NULL); POSTGRESQL_TEXT = DEFAULT.withDelimiter('\\t').withEscape(Constants.DOUBLE_QUOTE_CHAR).withIgnoreEmptyLines(false).withQuote(Constants.DOUBLE_QUOTE_CHAR).withRecordSeparator('\\n').withNullString(\"\\\\N\").withQuoteMode(QuoteMode.ALL_NON_NULL); RFC4180 = DEFAULT.withIgnoreEmptyLines(false); TDF = DEFAULT.withDelimiter('\\t').withIgnoreSurroundingSpaces();&#125; 不同的 Format 参数不一样而已，RFC4180 不会跳过空行，遇到空行会抛出异常","categories":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/categories/Java/"}],"tags":[{"name":"csv","slug":"csv","permalink":"http://j2go.github.io/tags/csv/"}]},{"title":"Spring Bean 生命周期","slug":"2017-09-14-spring-beans","date":"2017-09-15T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2017/09/15/2017-09-14-spring-beans/","link":"","permalink":"http://j2go.github.io/2017/09/15/2017-09-14-spring-beans/","excerpt":"","text":"实例化Spring 扫描包下所有类，对注解的 Bean 进行实例化 依赖注入Spring 将值和 Bean 的引用注入进 Bean 对应的属性中 setBeanName 回调如果 Bean 实现了 BeanNameAware 接口，Spring将Bean的ID传递给 setBeanName()方法（实现 BeanNameAware 主要是为了通过 Bean 的引用来获得 Bean 的 id，一般业务中是很少有用到 BeanId 的） setBeanDactory 回调如果 Bean 实现了 BeanFactoryAware 接口，Spring 将调用 setBeanDactory ( BeanFactory bf )方法并把 BeanFactory 容器实例作为参数传入。（实现 BeanFactoryAware 主要目的是为了获取 Spring 容器，如 Bean 通过 Spring 容器发布事件等） setApplicationContext 回调如果 Bean 实现了 ApplicationContextAwaer 接口，Spring 容器将调用 setApplicationContext(ApplicationContext ctx) 方法，把应用上下文作为参数传入。(作用与 BeanFactory 类似都是为了获取 Spring 容器，不同的是 Spring 容器在调用 setApplicationContext() 方法时会把它自己作为 setApplicationContext 的参数传入，而 Spring 容器在调用 setBeanDactory() 前需要程序员自己指定（注入）setBeanDactory 里的参数BeanFactory ) Bean 初始化前处理如果Bean实现了 BeanPostProcess 接口，Spring 将调用它们的 postProcessBeforeInitialization（预初始化）方法（作用是在 Bean 实例创建成功后对进行增强处理，如对 Bean 进行修改，增加某个功能） 容器启动完毕的回调如果 Bean 实现了 InitializingBean 接口，Spring 将调用它们的 afterPropertiesSet() 方法，作用与在配置文件中对 Bean 使用 init-method 声明初始化的作用一样，都是在 Bean 的全部属性设置成功后执行的初始化方法。 Bean 初始化后回调如果 Bean 实现了 BeanPostProcess 接口，Spring 将调用它们的 postProcessAfterInitialization() 方法 应用启动完毕经过以上的工作后，Bean将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁 Bean 销毁调用如果Bean实现了DispostbleBean接口，Spring将调用它的destory方法，作用与在配置文件中对Bean使用destory-method属性的作用一样，都是在Bean实例销毁前执行的方法。","categories":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/categories/Java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://j2go.github.io/tags/spring/"}]},{"title":"Shell 教程 - 看完就会","slug":"2017-03-05-shell-go","date":"2017-03-04T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2017/03/04/2017-03-05-shell-go/","link":"","permalink":"http://j2go.github.io/2017/03/04/2017-03-05-shell-go/","excerpt":"","text":"作为一个 Java 程序员，Go 爱好者，自然免不了天天和 Linux 打交道，也曾经写过一点点 shell 脚本，但是对那个反人类的语法深感厌恶，空格不对都不行。无奈项目需要一定要用 shell 来实现一个工具，学习的过程总是不那么顺风的，不过搞完之后也觉得没那么讨厌了。整理一下几天所得，希望能让一个从没写过 shell 但是还挺熟悉 Linux 的可以立马完成一个可用的脚本。 开始执行顺序 脚本顺序执行，原来怎么敲命令的就怎么写 变量赋值123456789# 变量赋值时等号两边不能有空格# 单引号是固定字符串pa='string'# 双引号可包含变量pb=\"ps is $&#123;pa&#125;\"# 接受命令返回pc=`ls -alh` 数组及其遍历12345678910111213141516171819 arr=(aa bb cc dd ff) # 通过下标访问 for ((i=0; i&lt;5; i++)) do echo \"$i: $&#123;arr[$i]&#125;\" done # 遍历访问 for s in $&#123;arr[@]&#125;do echo \" $s\" done # 空格分隔的字符串也能遍历，但是不能像上面的方式一样用下标访问元素 arr2='a1 a2 a3 a4 a5' for s in $&#123;arr2&#125;do echo $&#123;s&#125; done 条件判断12345678910111213141516# shell 脚本都是指令，if 的语句一定要注意空格# 第一种写法,下面输出 okif [[ 10 -gt 3 ]]; then echo ok; else echo no; fi# 第二种, ** 注意()： 下面输出 okif [ 2 &gt; 3 ]; then echo okfi# 第三种, 下面输出 noif [[ 2 &gt; 3 ]]then echo okelse echo nofi 定义函数12345678res=0echo $resadd() &#123; ((res = $1 + $2))&#125;add 12 13echo $res $? 说明12345678910111213# $?接受的是上一条命令执行后的返回值ls /home# 下面的输出是 0echo $?testReurn() &#123; return 8&#125;testReurn# 下面的输出是 8 echo $? 字符串操作123456789101112131415161718192021a='stringA'b='stringB'# 判断是否相等，下面输出 noif [[ $a == $b ]]; then echo yes; else echo no; fi# 字符串拼接， 下面输出 yesif [[ 'stringAstringB' == \"$&#123;a&#125;$&#123;b&#125;\" ]]; then echo yes; fi# 取字符串长度, 下面输出 7echo $&#123;#a&#125;# 截取字符串, 下面输出 string, ingecho \"$&#123;a:0:6&#125;, $&#123;a:3:3&#125;\"# 判断两个字符串是否有相同前缀, 下面输出 yesif [[ $&#123;a:0:5&#125; == $&#123;b:0:5&#125; ]]; then echo yes; else echo no; fi# 字符串切分为数组, IFS 变量指定分隔符, 分隔符前后空格会被略去IFS=, read -r -a arr &lt;&lt;&lt; 'a,b ,c, d,g e, ss'for str in $&#123;arr[@]&#125;; do echo \"'$&#123;str&#125;'\"; done 文件和目录判断123456789101112131415161718192021222324if [[ -f $filename ]]; then echo \"$filename 是一个文件\"elif [[ -d $filename ]]; then echo \"$filename 是一个目录\"elif [[ -p $filename ]]; then echo \"$filename 是一个管道文件\"elif [[ -S $filename ]]; then echo \"$filename 是一个 sokcet 文件\"elif [[ -b $filename ]]; then echo \"$filename 是 block device\"elif [[ -c $filename ]]; then echo \"$filename 是 character device\"fiif [[ -L $filename ]]; then echo \"$filename 是一个软链接\"fi# 对于软链接，使用-L测试时，当链接指向的目标文件不存在时会返回falseif [[ -L $filename || -e $filename ]]; then echo \"$filename 存在 (可能是失效的链接)\"fi if [[ -L $filename &amp;&amp; ! -e $filename ]]; then echo \"$filename 是失效的软链接\"fi 内容既输出到控制台也输出到文件里12echo 'ok'| tee -a bb.log 处理退出信号123456trap \"rm -f $&#123;lock_file&#125;; echo 'exited ok.'\" SIGINT SIGQUIT# SIGHUP：从终端终止或退出正在前台运行的进程# SIGINT：从键盘按下 Ctrl-C# SIGQUIT：从键盘按下 Ctrl-\\# SIGTERM ：软件终止信号 处理参数1234567891011121314151617181920212223242526272829 if [[ \"$OSTYPE\" == \"darwin\"* ]]; then # Mac OSX ( brew install gnu-getopt ) getopt_cmd=\"$(brew --prefix gnu-getopt)/bin/getopt\" else # linux-gnu getopt_cmd=\"getopt\" fi long_opts=\"once,name:,note:\" opts=$($getopt_cmd -n $0 -o - --long $long_opts -- \"$@\") eval set -- \"$opts\" while : do case \"$1\" in --once) once=\"true\" ; shift 1 ;; --name) name=$2 ; shift 2 ;; --note) note=$2 ; shift 2 ;; --) shift ; break ;; *) echo \"参数错误\" ; exit 1 ;; esacdoneecho \"once: $&#123;once:-no&#125;, name: $&#123;name&#125;, note: $&#123;note&#125;\" MySQL 查询12345678910111213std_log='/var/log/test.log'err_log='/var/log/test.err.log'user='root'pwd=''host='127.0.0.1'db='mysql'exec_sql() &#123; echo \"exec_sql: $1\" | tee -a $&#123;std_log&#125; mysql -u$&#123;user&#125; -p$&#123;pwd&#125; -h$&#123;host&#125; -D$&#123;db&#125; -s -N -e \"$1\" | tee -a $&#123;std_log&#125;&#125;exec_sql \"show databases\" 标准输入输出重定向 shell中，每个进程都和三个系统文件相关联：标准输入stdin，标准输出stdout和标准错误stderr，三个系统文件的文件描述符分别为0, 1, 2在使用 mysql 命令获取结果时会有一些警告信息mysql: [Warning] Using a password on the command line interface can be insecure.但是我要得到命令的结果不需要这些警告, 这个时候就需要重定向错误输出到其他地方num=`mysql -u${user} -p${pwd} -h${host} -D${db} -s -N -e &quot;${count_sql}&quot; 2&gt;${err_log} 注意此为个人这一周以来的小总结，并非专业的 shell 教程，旨在能帮助懂编程的人不会 shell 的能快速上手，少走一些我趟过的坑，减少一些搜索。有些原理我也不是太清楚，以后需要的时候才会去系统学习吧，现在这些已经能完成任务了。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://j2go.github.io/categories/Linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://j2go.github.io/tags/shell/"}]},{"title":"记一次代码重构","slug":"2017-02-07-download-refactoring","date":"2017-02-06T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2017/02/06/2017-02-07-download-refactoring/","link":"","permalink":"http://j2go.github.io/2017/02/06/2017-02-07-download-refactoring/","excerpt":"","text":"问题有这么一个下载 zip 文件的功能函数 函数的目的是要下载一个文件到指定目录，第一要检查大小，第二要检查是不是 zip 文件，然后下载到指定目录。现在的问题是这个没有超时控制，网络慢或者出问题的时候就死死的卡在那儿了 原代码1234567891011121314151617181920212223242526272829303132333435private File downloadZipFile(Task task) throws DeployScheduleException, IOException &#123; LOGGER.debug(\"#Scheduler#&#123;&#125;#download start\", task.getId()); HttpClient client = HttpClientBuilder.create().build(); HttpGet httpGet = new HttpGet(task.getArchive_url()); dbHelper.updateTaskStatusAndReason(task.getId(), \"FETCHING\", \"\"); HttpResponse response = client.execute(httpGet); long contentLength = response.getEntity().getContentLength(); long limit = sizeLimit &lt;&lt; 20; if (contentLength &gt; limit) &#123; dbHelper.updateTaskLog(task.getId(), \"Site archive size is more than \" + sizeLimit + \"M.\"); throw new DeployScheduleException(\"#Scheduler#\" + task.getId() + \"#Archive too big#size: &#123;&#125;\" + contentLength); &#125; String contentType = response.getEntity().getContentType().getValue(); if (!contentType.contains(\"octet-stream\") &amp;&amp; !contentType.contains(\"zip\") &amp;&amp; !task.getArchive_url().endsWith(\".zip\")) &#123; dbHelper.updateTaskLog(task.getId(), \"Project or branch not found.\"); throw new DeployScheduleException(\"#Scheduler#\" + task.getId() + \"#invalid content type: \" + contentType); &#125; InputStream inputStream = response.getEntity().getContent(); LOGGER.debug(\"tempPath\" + getTempOutFile(task)); FileOutputStream outFile = new FileOutputStream(getTempOutFile(task)); LOGGER.info(\"#Scheduler#&#123;&#125;#download file at &#123;&#125;\", task.getId(), getTempOutFile(task)); byte[] buffer=new byte[1024]; int ch; while ((ch = inputStream.read(buffer)) != -1) &#123; outFile.write(buffer,0,ch); &#125; inputStream.close(); outFile.flush(); outFile.close(); return new File(getTempOutFile(task));&#125; 第一个想法就是： 没超时控制，加上呗。 解决方案一12345678910111213141516171819202122232425262728//downloadTimeout= 1200sprivate File downloadZipFile(Task task) throws DeployScheduleException, IOException &#123; ... long start = System.currentTimeMillis(); String outFilePath = getTempOutFile(task); boolean successful = false; try (InputStream inputStream = response.getEntity().getContent(); FileOutputStream fos = new FileOutputStream(outFilePath)) &#123; LOGGER.info(\"#Scheduler#&#123;&#125;#download file at &#123;&#125;\", task.getId(), getTempOutFile(task)); byte[] buffer = new byte[1024]; int ch; while ((ch = inputStream.read(buffer)) != -1) &#123; fos.write(buffer, 0, ch); if (System.currentTimeMillis() - start &gt; downloadTimeout * 1000) &#123; throw new IOException(format(\"#Scheduler#%d#fetching timeout: %ds\", task.getId(), downloadTimeoutSeconds)); &#125; &#125; successful = true; fos.flush(); &#125; finally &#123; if (!successful) &#123; FileUtils.deleteQuietly(new File(outFilePath)); &#125; &#125; return new File(getTempOutFile(task));&#125; Review 时 大神们的意见就来了: timeout 加上单位吧 httpClient 自己有超时控制，自己造轮子有风险 判断条件长了语义化一下比较好 嗯嗯嗯，有道理，改改改。。。 解决方案二1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//downloadTimeoutSeconds= 1200sprivate File downloadZipFile(Task task) throws DeployScheduleException, IOException &#123; LOGGER.debug(\"#Scheduler#&#123;&#125;#download start\", task.getId()); SocketConfig socketConfig = SocketConfig.custom() .setSoTimeout(downloadTimeoutSeconds * 1000) .build(); HttpGet httpGet = new HttpGet(task.getArchive_url()); final String tempOutFile = getTempOutFile(task); try(CloseableHttpClient client = HttpClientBuilder.create().setDefaultSocketConfig(socketConfig).build()) &#123; dbHelper.updateTaskStatusAndReason(task.getId(), \"FETCHING\", \"\"); HttpEntity resEntity = client.execute(httpGet).getEntity(); long contentLength = resEntity.getContentLength(); long limit = sizeLimit &lt;&lt; 20; if (contentLength &gt; limit) &#123; dbHelper.updateTaskLog(task.getId(), \"Site archive size is more than \" + sizeLimit + \"M.\"); throw new DeployScheduleException(\"#Scheduler#\" + task.getId() + \"#Archive too big#size: &#123;&#125;\" + contentLength); &#125; String contentType = resEntity.getContentType().getValue(); if (isZipFile(task, contentType)) &#123; dbHelper.updateTaskLog(task.getId(), \"Project or branch not found.\"); throw new DeployScheduleException(\"#Scheduler#\" + task.getId() + \"#invalid content type: \" + contentType); &#125; try (InputStream inputStream = response.getEntity().getContent(); FileOutputStream fos = new FileOutputStream(outFilePath)) &#123; LOGGER.info(\"#Scheduler#&#123;&#125;#download file at &#123;&#125;\", task.getId(), getTempOutFile(task)); byte[] buffer = new byte[1024]; int ch; while ((ch = inputStream.read(buffer)) != -1) &#123; fos.write(buffer, 0, ch); if (System.currentTimeMillis() - start &gt; downloadTimeout * 1000) &#123; throw new IOException(format(\"#Scheduler#%d#fetching timeout: %ds\", task.getId(), downloadTimeoutSeconds)); &#125; &#125; fos.flush(); &#125; &#125; catch (SocketTimeoutException e) &#123; FileUtils.deleteQuietly(new File(tempOutFile)); throw new IOException(String.format(\"#Scheduler#%d#fetching timeout: %ds\", task.getId(), downloadTimeoutSeconds)); &#125; return new File(tempOutFile); &#125; private boolean isZipFile(Task task, String contentType) &#123; return !contentType.contains(\"octet-stream\") &amp;&amp; !contentType.contains(\"zip\") &amp;&amp; !task.getArchive_url().endsWith(\".zip\"); &#125; 这下应该没问题了吧，继续提交又有人质疑了这段1234567891011121314try (InputStream inputStream = response.getEntity().getContent(); FileOutputStream fos = new FileOutputStream(outFilePath)) &#123; LOGGER.info(&quot;#Scheduler#&#123;&#125;#download file at &#123;&#125;&quot;, task.getId(), getTempOutFile(task)); byte[] buffer = new byte[1024]; int ch; while ((ch = inputStream.read(buffer)) != -1) &#123; fos.write(buffer, 0, ch); if (System.currentTimeMillis() - start &gt; downloadTimeout * 1000) &#123; throw new IOException(format(&quot;#Scheduler#%d#fetching timeout: %ds&quot;, task.getId(), downloadTimeoutSeconds)); &#125; &#125; fos.flush();&#125; 都什么时候还用这么原始的方式， JDK nio 啊，Files.copy() 一下搞定，还不比你写的优秀啊 去翻翻源码还真有这么个1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Copies all bytes from an input stream to a file. On return, the input * stream will be at end of stream. * * &lt;p&gt; By default, the copy fails if the target file already exists or is a * symbolic link. If the &#123;@link StandardCopyOption#REPLACE_EXISTING * REPLACE_EXISTING&#125; option is specified, and the target file already exists, * then it is replaced if it is not a non-empty directory. If the target * file exists and is a symbolic link, then the symbolic link is replaced. * In this release, the &#123;@code REPLACE_EXISTING&#125; option is the only option * required to be supported by this method. Additional options may be * supported in future releases. * * &lt;p&gt; If an I/O error occurs reading from the input stream or writing to * the file, then it may do so after the target file has been created and * after some bytes have been read or written. Consequently the input * stream may not be at end of stream and may be in an inconsistent state. * It is strongly recommended that the input stream be promptly closed if an * I/O error occurs. * * &lt;p&gt; This method may block indefinitely reading from the input stream (or * writing to the file). The behavior for the case that the input stream is * &lt;i&gt;asynchronously closed&lt;/i&gt; or the thread interrupted during the copy is * highly input stream and file system provider specific and therefore not * specified. * * &lt;p&gt; &lt;b&gt;Usage example&lt;/b&gt;: Suppose we want to capture a web page and save * it to a file: * &lt;pre&gt; * Path path = ... * URI u = URI.create(&quot;http://java.sun.com/&quot;); * try (InputStream in = u.toURL().openStream()) &#123; * Files.copy(in, path); * &#125; * &lt;/pre&gt; * * @param in * the input stream to read from * @param target * the path to the file * @param options * options specifying how the copy should be done * * @return the number of bytes read or written * * @throws IOException * if an I/O error occurs when reading or writing * @throws FileAlreadyExistsException * if the target file exists but cannot be replaced because the * &#123;@code REPLACE_EXISTING&#125; option is not specified &lt;i&gt;(optional * specific exception)&lt;/i&gt; * @throws DirectoryNotEmptyException * the &#123;@code REPLACE_EXISTING&#125; option is specified but the file * cannot be replaced because it is a non-empty directory * &lt;i&gt;(optional specific exception)&lt;/i&gt; * * @throws UnsupportedOperationException * if &#123;@code options&#125; contains a copy option that is not supported * @throws SecurityException * In the case of the default provider, and a security manager is * installed, the &#123;@link SecurityManager#checkWrite(String) checkWrite&#125; * method is invoked to check write access to the file. Where the * &#123;@code REPLACE_EXISTING&#125; option is specified, the security * manager&apos;s &#123;@link SecurityManager#checkDelete(String) checkDelete&#125; * method is invoked to check that an existing file can be deleted. */public static long copy(InputStream in, Path target, CopyOption... options) throws IOException&#123;...&#125; 最后忽然觉得用 throw 来终止过程好像还可以精简。哟西，最终结果出炉。 最终结果12345678910111213141516171819202122232425262728293031323334353637383940414243444546private File downloadZipFile(Task task) throws DeployScheduleException, IOException &#123; LOGGER.debug(\"#Scheduler#&#123;&#125;#download start\", task.getId()); SocketConfig socketConfig = SocketConfig.custom() .setSoTimeout(downloadTimeoutSeconds * 1000) .build(); HttpGet httpGet = new HttpGet(task.getArchive_url()); final String tempOutFile = getTempOutFile(task); try(CloseableHttpClient client = HttpClientBuilder.create().setDefaultSocketConfig(socketConfig).build()) &#123; dbHelper.updateTaskStatusAndReason(task.getId(), \"FETCHING\", \"\"); HttpEntity responseEntity = client.execute(httpGet).getEntity(); checkContentLength(task, responseEntity); checkContentType(task, responseEntity); try (InputStream inputStream = responseEntity.getContent()) &#123; Files.copy(inputStream, Paths.get(tempOutFile), StandardCopyOption.REPLACE_EXISTING); &#125; &#125; catch (SocketTimeoutException e) &#123; FileUtils.deleteQuietly(new File(tempOutFile)); throw new IOException(String.format(\"#Scheduler#%d#fetching timeout: %ds\", task.getId(), downloadTimeoutSeconds)); &#125; return new File(tempOutFile);&#125;private void checkContentType(Task task, HttpEntity resEntity) throws DeployScheduleException &#123; String contentType = resEntity.getContentType().getValue(); if (isZipFile(task, contentType)) &#123; dbHelper.updateTaskLog(task.getId(), \"Project or branch not found.\"); throw new DeployScheduleException(\"#Scheduler#\" + task.getId() + \"#invalid content type: \" + contentType); &#125;&#125;private void checkContentLength(Task task, HttpEntity resEntity) throws DeployScheduleException &#123; long contentLength = resEntity.getContentLength(); // 1 &lt;&lt; 20 = 1M long limit = sizeLimit &lt;&lt; 20; if (contentLength &gt; limit) &#123; dbHelper.updateTaskLog(task.getId(), \"Site archive size is more than \" + sizeLimit + \"M.\"); throw new DeployScheduleException(\"#Scheduler#\" + task.getId() + \"#Archive too big#size: &#123;&#125;\" + contentLength); &#125;&#125;private boolean isZipFile(Task task, String contentType) &#123; return !contentType.contains(\"octet-stream\") &amp;&amp; !contentType.contains(\"zip\") &amp;&amp; !task.getArchive_url().endsWith(\".zip\");&#125; 重构小结 对类库的使用要熟悉，多测试，少写很多代码而且语义清晰 长判断条件提炼方法，语义化更方便看 要多看看 JDK 的东西，很多基础的操作里面都有 配置参数如果有单位最好加上单位，减少使用风险","categories":[{"name":"重构","slug":"重构","permalink":"http://j2go.github.io/categories/重构/"}],"tags":[{"name":"重构","slug":"重构","permalink":"http://j2go.github.io/tags/重构/"}]},{"title":"file-leak-detector 检查Java文件句柄泄露","slug":"2017-01-02-file-leak-detector","date":"2017-01-01T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2017/01/01/2017-01-02-file-leak-detector/","link":"","permalink":"http://j2go.github.io/2017/01/01/2017-01-02-file-leak-detector/","excerpt":"","text":"维护 WEB-IDE 免不了要管理很多的文件， 自从我们 线上的系统增加了资源回收功能，便一直受一个问题困扰，后台线程解绑目录时偶尔报错，看症状因为是某些文件被占用了，目录不能解绑。但是由于系统中很多地方都有打开文件，各种包也存在复杂的的引用关系，在搜查几遍代码后并没有发现什么明显的异常。 由于这个功能清理的是既没在线又没有在离线列表中的磁盘绑定目录，那么很可能是文件句柄泄露了，还有一种原因可能是 JVM 延迟释放文件句柄，不过实际是什么原因还需要用数据说话。 经过一番搜索，发一个工具叫 file-leak-detector， 可以监控什么线程在什么时候打开了哪儿的文件，看起来好酷，官网在这里：http://file-leak-detector.kohsuke.org 使用方式监听 HTTP 端口方式启动以 javaagent 方式启动一个 jar 文件，输出在 http 19999 端口。1$java -javaagent:./file-leak-detector-1.8-jar-with-dependencies.jar=http=19999 -jar ide-backend.jar 然后直接在浏览器访问刚刚启动时配置的 http端口： 图片 可以看到当前所有打开中的文件的堆栈信息。 配置参数启动配置线程数量限制,在文件句柄持有数超过设定数值时输出所有文件打开时的堆栈信息到 System 的 err 日志中。1$ java -javaagent:path/to/file-leak-detector.jar=threshold=200 ...your usual Java args follows... Attach 方式启动启动后直接被加载到运行中的 JAVA 进程里。1$ java -jar path/to/file-leak-detector.jar 1500 threshold=200,strong strong 代表的含义是把记录信息的应用变成强引用，防止被 GC 回收掉，不设置在内存不足时文件记录会丢失。 实际使用体验首先我们在测试服务器上部署端口来监控，然后进行各种测试，最后确实找到几处未关闭的代码。1$java -javaagent:./file-leak-detector-1.8-jar-with-dependencies.jar=http=19999 -jar xxx.jar 不过有一点比较不爽，绑定的地址是固定的 localhost, 远程的就不能访问。123╭─tiangao@tgmbp ~/git/tiangao ‹master*›╰─$ curl 192.168.31.227:19999curl: (7) Failed to connect to 192.168.31.227 port 19999: Connection refused 这个先放一边，官网说还可以 attach 到正在运行的进程中，这点才是我们到线上监控所需要的，有些问题只有在线上才会出现。 不过官网里并没有发现怎么挂到正在运行中的 java 程序并开启 http 端口输出，而且监听的端口只有 localhost。这就让我们感觉有点怪异，也许有安全性的考量吧，只好去看看源码，才知道怎么个用法，为了更方便还改了下监听的 host，以便远程可以访问。 AgentMain.java123456private static void runHttpServer(int port) throws IOException &#123; final ServerSocket ss = new ServerSocket(); ss.bind(new InetSocketAddress(&quot;0.0.0.0&quot;, port)); System.err.println(&quot;Serving file leak stats on http://0.0.0.0:&quot;+ss.getLocalPort()+&quot;/ for stats&quot;); ...&#125; 改之后使用如下所示:123root@staging-1:~# java -jar file-leak-detector-1.8-jar-with-dependencies.jar 612 http=19999Connecting to 612Activating file leak detector at /root/file-leak-detector-1.8-jar-with-dependencies.jar 612 是 java 服务的进程号，19999 是监听的 http 端口号。 执行后输出类似如下内容时即表示 attach 到进程成功。1234╭─tiangao@tgmbp ~/git/WebIDE-Backend/target ‹master*›╰─$ java -jar file-leak-detector-1.8-jar-with-dependencies.jar 93739Connecting to 93739Activating file leak detector at /Users/shitiangao/git/WebIDE-Backend/target/file-leak-detector-1.8-jar-with-dependencies.jar 然后通过地址加端口就可以访问,就可以显示进程在 attach 之后打开的文件以及相应堆栈信息。1234563 descriptors are open#1 /opt/coding-ide-home/ide-backend.jar by thread:qtp873134840-16 on Tue Nov 29 15:05:34 CST 2016 at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:244) at org.springframework.boot.loader.data.RandomAccessDataFile$FilePool.acquire(RandomAccessDataFile.java:252) at org.springframework.boot.loader.data.RandomAccessDataFile$DataInputStream.doRead(RandomAccessDataFile.java:174) at org.springframework.boot.loader.data.RandomAccessDataFile$DataInputStream.read(RandomAccessDataFile.java:152) 如此改动测试后在本地好用，但是一到线上部署就报错了：1234567891011121314pid: 13546Connecting to 13546Exception in thread &quot;main&quot; java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.kohsuke.file_leak_detector.Main.run(Main.java:54) at org.kohsuke.file_leak_detector.Main.main(Main.java:39)Caused by: com.sun.tools.attach.AttachNotSupportedException: Unable to open socket file: target process not responding or HotSpot VM not loaded at sun.tools.attach.LinuxVirtualMachine.&lt;init&gt;(LinuxVirtualMachine.java:106) at sun.tools.attach.LinuxAttachProvider.attachVirtualMachine(LinuxAttachProvider.java:63) at com.sun.tools.attach.VirtualMachine.attach(VirtualMachine.java:208) ... 6 more 目测原因是 JVM 运行时反射加载不到类。 第一感觉需要设置一下 JAVA_HOME, 然而结果证明并不是这个原因。 万能的 google &amp; stackoverflow 找到了解法：java - AttachNotSupportedException due to missing java_pid file in Attach API 执行 attach 的用户需要和 Java 服务运行用户是同一个，另外 JAVA_HOME 环境变量还是需要的。 终于成功了，接下来就是等待错误的再次发生，然后分析堆栈信息了。 如此好用的工具是让我们对其原理很好奇。 工作原理项目源码并不是太多，先看 main ：123456789101112131415public static void main(String[] args) throws Exception &#123; Main main = new Main(); CmdLineParser p = new CmdLineParser(main); try &#123; p.parseArgument(args); main.run(); &#125; catch (CmdLineException e) &#123; System.err.println(e.getMessage()); System.err.println(&quot;java -jar file-leak-detector.jar PID [OPTSTR]&quot;); p.printUsage(System.err); System.err.println(&quot;\\nOptions:&quot;); AgentMain.printOptions(); System.exit(1); &#125; &#125; 来到 run() 方法，123456789101112131415public void run() throws Exception &#123; Class api = loadAttachApi(); System.out.println(&quot;Connecting to &quot;+pid); Object vm = api.getMethod(&quot;attach&quot;,String.class).invoke(null,pid); try &#123; File agentJar = whichJar(getClass()); System.out.println(&quot;Activating file leak detector at &quot;+agentJar); // load a specified agent onto the JVM api.getMethod(&quot;loadAgent&quot;,String.class,String.class).invoke(vm, agentJar.getPath(), options); &#125; finally &#123; api.getMethod(&quot;detach&quot;).invoke(vm); &#125;&#125; 通过 loadAttachApi() 得到 VirtualMachine 类，然后再用反射获取 attach() 方法，紧接着执行 attach() 到指定进程 id 上，得到 vm 的实例后执行 loadAgent() 方法，第一个参数为 agentJar 包的路径，第二个 options 是附加参数。 loadAttachApi() 方法如下： 12345678910private Class loadAttachApi() throws MalformedURLException, ClassNotFoundException &#123; File toolsJar = locateToolsJar(); ClassLoader cl = wrapIntoClassLoader(toolsJar); try &#123; return cl.loadClass(&quot;com.sun.tools.attach.VirtualMachine&quot;); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(&quot;Unable to find tools.jar at &quot;+toolsJar+&quot; --- you need to run this tool with a JDK&quot;,e); &#125;&#125; 问题来了，VirtualMachine 是个什么功能的类？ attach() loadAgent() 又是什么作用呢？ 这个就涉及到 JVM 层面提供的功能，在这之前也没有研究过，只好看看大拿的研究。 InfoQ JVM源码分析之javaagent原理完全解读 关键类 Instrument: Package java.lang.instrument 简单总结，JVM 暴露了一些动态操作已加载类型的接口，javaagnet 就是利用这些接口的一个实现，通过 agent 类的固定方法可以执行一些操作，比如对已经加载的类注入字节码，最常用的是用来监控运行时，进行一些疑难 bug 追踪。 此项目里 TransformerImpl 类就是字节码修改的实现类。 关键源码：12345678instrumentation.addTransformer(new TransformerImpl(createSpec()),true); instrumentation.retransformClasses( FileInputStream.class, FileOutputStream.class, RandomAccessFile.class, Class.forName(&quot;java.net.PlainSocketImpl&quot;), ZipFile.class); 可以看到注册的类有 FileInputStream、FileOutputStream、RandomAccessFile、ZipFile 和 PlainSocketImpl。 1234567891011121314151617181920212223242526272829303132333435static List&lt;ClassTransformSpec&gt; createSpec() &#123; return Arrays.asList( newSpec(FileOutputStream.class, &quot;(Ljava/io/File;Z)V&quot;), newSpec(FileInputStream.class, &quot;(Ljava/io/File;)V&quot;), newSpec(RandomAccessFile.class, &quot;(Ljava/io/File;Ljava/lang/String;)V&quot;), newSpec(ZipFile.class, &quot;(Ljava/io/File;I)V&quot;), /* java.net.Socket/ServerSocket uses SocketImpl, and this is where FileDescriptors are actually managed. SocketInputStream/SocketOutputStream does not maintain a separate FileDescritor. They just all piggy back on the same SocketImpl instance. */ new ClassTransformSpec(&quot;java/net/PlainSocketImpl&quot;, // this is where a new file descriptor is allocated. // it&apos;ll occupy a socket even before it gets connected new OpenSocketInterceptor(&quot;create&quot;, &quot;(Z)V&quot;), // When a socket is accepted, it goes to &quot;accept(SocketImpl s)&quot; // where &apos;s&apos; is the new socket and &apos;this&apos; is the server socket new AcceptInterceptor(&quot;accept&quot;,&quot;(Ljava/net/SocketImpl;)V&quot;), // file descriptor actually get closed in socketClose() // socketPreClose() appears to do something similar, but if you read the source code // of the native socketClose0() method, then you see that it actually doesn&apos;t close // a file descriptor. new CloseInterceptor(&quot;socketClose&quot;) ), new ClassTransformSpec(&quot;sun/nio/ch/SocketChannelImpl&quot;, new OpenSocketInterceptor(&quot;&lt;init&gt;&quot;, &quot;(Ljava/nio/channels/spi/SelectorProvider;)V&quot;), new CloseInterceptor(&quot;kill&quot;) ) );&#125; ClassTransformSpec 定义：1234567891011/** * Creates &#123;@link ClassTransformSpec&#125; that intercepts * a constructor and the close method. */private static ClassTransformSpec newSpec(final Class c, String constructorDesc) &#123; final String binName = c.getName().replace(&apos;.&apos;, &apos;/&apos;); return new ClassTransformSpec(binName, new ConstructorOpenInterceptor(constructorDesc, binName), new CloseInterceptor() );&#125; 关键真相在这里，实现了一个方法拦截适配器，在注册类的某些方法执行后运行 Listener 类的 open() 方法来记录信息。123456789101112131415161718192021222324252627282930313233343536/** * Intercepts the this.open(...) call in the constructor. */private static class ConstructorOpenInterceptor extends MethodAppender &#123; /** * Binary name of the class being transformed. */ private final String binName; public ConstructorOpenInterceptor(String constructorDesc, String binName) &#123; super(&quot;&lt;init&gt;&quot;, constructorDesc); this.binName = binName; &#125; @Override public MethodVisitor newAdapter(MethodVisitor base, int access, String name, String desc, String signature, String[] exceptions) &#123; final MethodVisitor b = super.newAdapter(base, access, name, desc, signature, exceptions); return new OpenInterceptionAdapter(b,access,desc) &#123; @Override protected boolean toIntercept(String owner, String name) &#123; return owner.equals(binName) &amp;&amp; name.startsWith(&quot;open&quot;); &#125; @Override protected Class&lt;? extends Exception&gt; getExpectedException() &#123; return FileNotFoundException.class; &#125; &#125;; &#125; protected void append(CodeGenerator g) &#123; g.invokeAppStatic(Listener.class,&quot;open&quot;, new Class[]&#123;Object.class, File.class&#125;, new int[]&#123;0,1&#125;); &#125;&#125; 最后的 append() 方法可以说是整个流程中最核心的地方，Listener#open() 方法如下所示： 123456789 public static synchronized void open(Object _this, File f) &#123; put(_this, new Listener.FileRecord(f)); Iterator i$ = ActivityListener.LIST.iterator(); while(i$.hasNext()) &#123; ActivityListener al = (ActivityListener)i$.next(); al.open(_this, f); &#125;&#125; 最后说 一下 Listener 这个类，这也是这个工具的一个关键的类实现，有许多静态方法，所有监控的打开的文件相关内容都在 Listener 中保存，内容输出的操作也在其中。 这是类中的属性和方法: TABLE 保存打开中的文件，默认是 weak 引用，内存不足时这个对象会被回收掉，以防止程序不会因为监控导致的内存不足而异常退出。当参数 strong 存在时会 new 一个 LinkedHashMap, 让监控内容的容器不会被回收掉。 1234 /** * Files that are currently open, keyed by the owner object (like &#123;@link FileInputStream&#125;. */private static Map&lt;Object,Record&gt; TABLE = new WeakHashMap&lt;Object,Record&gt;(); Record 中有三个字段，一个是用来保存堆栈信息的异常类型，一个是线程名，最后一个是时间。 123456789/** * Remembers who/where/when opened a file. */public static class Record &#123; public final Exception stackTrace = new Exception(); public final String threadName; public final long time; ...&#125; 到这里已经差不多了，其他细节实现也就不赘述了。 小结file-leak-detector 查找文件句柄泄露问题，就是用 JVM 提供的接口，以 agent 方式 attach 进正在运行的 JAVA 进程，修改 FileStream 等类型的字节码，在 open &amp; close 文件时加入拦截操作，记录线程和堆栈，然后在 http 或者 系统日志中输出记录。最后通过这些信息查找是哪里导致的问题，然后做针对性的修复。","categories":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/categories/Java/"}],"tags":[{"name":"IO","slug":"IO","permalink":"http://j2go.github.io/tags/IO/"}]},{"title":"查看 IPhone 电池信息","slug":"2017-01-26-iphone-battery","date":"2016-12-31T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/12/31/2017-01-26-iphone-battery/","link":"","permalink":"http://j2go.github.io/2016/12/31/2017-01-26-iphone-battery/","excerpt":"","text":"不需要其他第三方软件 打开设置 图片 图片 图片 图片 打开日志文件 电池循环次数 电池容量","categories":[{"name":"Other","slug":"Other","permalink":"http://j2go.github.io/categories/Other/"}],"tags":[{"name":"iphone","slug":"iphone","permalink":"http://j2go.github.io/tags/iphone/"}]},{"title":"Spring Cloud Config","slug":"2016-12-01-cloud-config","date":"2016-11-30T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/11/30/2016-12-01-cloud-config/","link":"","permalink":"http://j2go.github.io/2016/11/30/2016-12-01-cloud-config/","excerpt":"","text":"背景现今这个时候，微服务大行其道，互联网应用遍地都是，随便开发个什么应用首要考虑的都是要可伸缩，扩展性要好。当我们的后台服务一点点增多，各个服务的配置也越来越多，随之而来的就是一个配置管理问题，各自管各自的开发时没什么问题，到了线上之后管理就会很头疼，到了要大规模更新的时候就更烦了。我们的后台服务就是如此，各种语言开发的都有，在慢慢的迭代过程的我们发现配置中心是一个比较好的解决方案，作为 Spring 的拥趸我们自然就看中了 Spring Cloud Config。一般服务器的应用都有以下几种类型: 图片 其中当属业务部分最多也最繁杂。当应用变得越来越庞大和复杂时，单机就肯定不能满足需求了，然后就要考虑分布式了，接下去还可能会应用不同的语言来开发应用。 比如 nginx 毫无疑问的是用的最多的反向代理组件，使用 OpenResty 便要用到 lua，再比如前端要 seo ，一个解决办法就是使用 nodejs，到了后端分布式，那就更繁多了，可能会需要把业务一个个拆分成不同的服务单独运行…然后就发现散落一地的配置文件，properties、yml、json … 为了解决这个问题，我们采取了这么一种方案，通过 etcd 来收集所有的配置，然后统一的写到一个文件中去，任何应用都来访问这一个文件来找到自己的配置并应用。 图片 这很好的解决了配置散落的问题，可以集中管理了，但是又一个问题来了，各种类型的配置在一个文件里看起来好乱，而且在初始化时必须要完成这个文件才能启动应用。 解决方案所以下一个解决方案便想到用一个配置中心来搞定。 Spring Cloud Config 项目 提供 服务端 和 客户端 支持 集中式 管理分布式环境下的应用配置 基于 Spring 环境，无缝 与 Spring 应用集成 可用于 任何 语言开发的程序 默认实现基于 git 仓库，可以进行 版本管理 可替换 自定义实现 Spring Cloud Config Server作为配置中心服务端 拉取配置时更新 git 仓库副本，保证是最新结果 支持数据结构丰富，yml, json, properties 等 配合 eureke 可实现服务发现，配合 cloud bus 可实现配置推送更新 配置存储基于 git 仓库，可进行版本管理 简单可靠，有丰富的配套方案 Spring Cloud Config Client默认客户端实现 SpringBoot 项目不需要改动任何代码，加入一个启动配置文件指明使用 ConfigServer 上哪个配置文件即可 简单使用示例新建仓库新建一个 git 仓库，添加一个配置文件。例如想要一个 billing的服务，性质是开发，运行环境是测试环境。那么就新建一个 testing 的分支，然后提交一个 billing-dev.properties 的文件1234567devMode = truespring.application.name = billingspring.jdbc.host = localhostspring.jdbc.port = 3306spring.jdbc.user = rootspring.jdbc.password = 123qweloging.file = demo 新建一个标准 maven 项目 图片 ConfigServer.java 1234567@SpringBootApplication@EnableConfigServerpublic class ConfigServer &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigServer.class, args); &#125;&#125; application.yml123456789server: port: 8888spring: cloud: config: server: git: uri:https://git.coding.net/tiangao/demo-config-server.git clone-on-start: true pom.xml123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;config-server&lt;/artifactId&gt; &lt;version&gt;0.1.0&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-config-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;1.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动效果 配置中心已经可以启动,最简单的访问方式可以访问浏览器。 图片 想要 json 格式的怎么办呢 图片 还有 yml, properties 图片 图片 安全配置 添加 Security 依赖，配置用户名和密码访问，毕竟直接通过 url 就可以访问太不安全了。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 然后在 application.yml 中配置用户名密码。123security: user: password: db1ab002-1fba-476d-a421-22113355 再访问就能看到如下的效果 图片 以上就是 ConfigSever 默认实现的基本的 HttpBasic 的认证 客户端配置SpringBoot 客户端配置，仅仅只需要添加一个启动配置文件。123456789spring: cloud: config: uri: http://127.0.0.1:8888 profile: dev label: testing name: billing password: db1ab002-1fba-476d-a421-22113355 username: user 当启动时看到下面标示的内容是即表示加载成功 图片 流程示意图 图片 配置加载源所有的配置都通过仓库来管理，应用启动时访问配置中心能拿到自己的配置即可加载，接下来再进入各自的初始化过程。仓库也不仅仅只能用 git, 还有 svn 和本地目录可以选择 svn://${user.home}/config-repo file://${user.home}/config-repo 疑问从上面的简单使用里可以看出，我们只要提交一种格式的配置文件，通过不同的方式访问即可得到不同格式的配置文件，真棒。那么这在ConfigServer里是如何实现的呢？ 原理探究访问方式首先看一共有多少种访问方式 /{name}/{profiles:.[^-].} /{name}/{profiles}/{label:.*} /{name}-{profiles}.properties /{label}/{name} /{profiles}.properties /{name}-{profiles}.json /{label}/{name}-{profiles}.json name 可以代表应用名，profiles 是属性，可以用来甄别是什么用途，label 就是 git 的标签了，大约可以用来指明环境。接下来再看就转到这么一个包含各种资源类型的转换操作的集合类上面，同时暴露资源接口。其中方法如下图所示： 原来内部只存在一种资源抽象： 图片 资源抽象实现一个应用的配置只需要应用名、属性和标签就可以定位到。嗯，原来这么简单，那 EnvironmentReposiroty 又是哪里实现呢？ 扒扒类图： 图片 findOne() 方法在 AbstractScmEnvironmentRepository 中可以找到12345678910@Overridepublic synchronized Environment findOne(String application, String profile, String label) &#123; NativeEnvironmentRepository delegate = new NativeEnvironmentRepository(getEnvironment()); Locations locations = getLocations(application, profile, label); delegate.setSearchLocations(locations.getLocations()); Environment result = delegate.findOne(application, profile, &quot;&quot;); result.setVersion(locations.getVersion()); result.setLabel(label); return this.cleaner.clean(result, getWorkingDirectory().toURI().toString(), getUri());&#125; 这其中又由 SearcPathLocator 接口的 getLocations() 来实际加载内容,这个方法就由具体的实现类来完成。Spring Cloud Config Server 内部除了 JGitEnvironmentRepository 实现外还有另外三种实现。 SvnKitEnvironmentRepository NativeEnvironmentRepository MultipleJGitEnvironmentRepository 见名知其意，分别是 svn 本地目录以及多 git 仓库的实现，具体内容就不细说，大家有兴趣可自行研究。 客户端加载原理项目只需要加载依赖就可以使用远程配置，现有项目迁移过去也不用改动任何代码，刚使用的时候感觉真是爽快。达到这样的效果背后依赖于 SpringMVC 自身的优秀的抽象实现以及 Springboot 的实用的自动配置类加载。12345678910111213141516@Configurationpublic class ConfigClientAutoConfiguration &#123; @Bean public ConfigClientProperties configClientProperties( Environment environment, ApplicationContext context) &#123;...&#125; ... @Bean public ConfigServerHealthIndicator configServerHealthIndicator( ConfigServicePropertySourceLocator locator, ConfigClientHealthProperties properties, Environment environment) &#123; return new ConfigServerHealthIndicator(locator, environment, properties); &#125; ...&#125; 无关的逻辑部分在这里就省去了，接着看。ConfigClientAutoConfiguration 这个是 ConfigClient 的自动配置类,加载时触发新建一个 ConfigServicePropertySourceLocator 的 bean。123456789101112131415161718@Order(0)public class ConfigServicePropertySourceLocator implements PropertySourceLocator &#123; private RestTemplate restTemplate; private ConfigClientProperties defaultProperties; ... @Override @Retryable(interceptor = &quot;configServerRetryInterceptor&quot;) public org.springframework.core.env.PropertySource&lt;?&gt; locate( org.springframework.core.env.Environment environment) &#123; ... // Try all the labels until one works for (String label : labels) &#123; Environment result = getRemoteEnvironment(restTemplate, properties, label.trim(), state); ...&#125; 然后在 ApplicationContextInitializer 的 initialize() 方法中被调用 locate() 方法从 ConfigServer 拉取配置文件，注入到 ConfigurableEnvironment 里。 1234567891011121314151617181920@Configuration@EnableConfigurationProperties(PropertySourceBootstrapProperties.class)public class PropertySourceBootstrapConfiguration implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered &#123; ... @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; ... ConfigurableEnvironment environment = applicationContext.getEnvironment(); for (PropertySourceLocator locator : this.propertySourceLocators) &#123; PropertySource&lt;?&gt; source = null; source = locator.locate(environment); if (source == null) &#123; continue; &#125; ... &#125; ... &#125;&#125; 接下来才进入应用的初始化过程。从以上过程可以看到，其他任何应用需要使用 ConfigServer 时也只需要在应用初始化之前通过 HTTP 请求拉取到配置文件即可。 小结了解了大致原理，便可以捋一捋集中式管理的优点。 图片 没有记忆负担：大家都使用一个仓库保存所有配置文件，方便查看。 降低冲突沟通成本：开发新功能是凡是有配置变动均向仓库的提交，在合并后其他人碰到配置问题时也不用到处找人问，看看仓库历史就知道什么发生了变化。 方便测试：测试环境下，测试人员也不用老是问开发环境配置的问题了，所有配置一目了然，更改记录也都有提交说明，有问题向开发反馈也能帮助快速定位问题范围。 方便管理： 在模拟环境和生产环境下，由运维人员管理线上配置文件，只要设置好分支保护和权限分配。","categories":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/categories/Java/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://j2go.github.io/tags/SpringCloud/"}]},{"title":"Java7 文件夹操作","slug":"2016-11-30-Java7-file-op","date":"2016-11-29T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/11/29/2016-11-30-Java7-file-op/","link":"","permalink":"http://j2go.github.io/2016/11/29/2016-11-30-Java7-file-op/","excerpt":"","text":"复制文件夹 &amp; 删除文件夹12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public static void copy(String src, String dst) throws IOException &#123; final Path srcPath = Paths.get(src); Path destPath = Paths.get(dst); if (Files.notExists(destPath)) &#123; Files.createDirectory(destPath); &#125; Files.walkFileTree(srcPath, new FileVisitor&lt;Path&gt;() &#123; @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException &#123; String dirStr = dir.toString(); String r = dirStr.substring(src.length(), dirStr.length()); Path dstPath = Paths.get(dst, r); if (Files.notExists(dstPath)) &#123; Files.createDirectory(dstPath); &#125; return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; String pathStr = file.toString(); String relative = pathStr.substring(src.length(), pathStr.length()); String destFile = Paths.get(dst, relative).toString(); Files.copy(file, new FileOutputStream(destFile)); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException &#123; return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException &#123; return FileVisitResult.CONTINUE; &#125; &#125;);&#125;public static void clean(Path path) throws IOException &#123; if (!Files.exists(path)) &#123; return; &#125; if (!Files.isDirectory(path)) &#123; Files.delete(path); return; &#125; Files.walkFileTree(path, new FileVisitor&lt;Path&gt;() &#123; @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException &#123; return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; Files.delete(file); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException &#123; throw exc; &#125; @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException &#123; Files.delete(dir); return FileVisitResult.CONTINUE; &#125; &#125;);&#125; 不过这个似乎有些问题，如果碰到有软链的情况怎么办？","categories":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/categories/Java/"}],"tags":[{"name":"IO","slug":"IO","permalink":"http://j2go.github.io/tags/IO/"}]},{"title":"Golang 稀疏文件处理","slug":"2016-11-05-go-sparse","date":"2016-11-04T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/11/04/2016-11-05-go-sparse/","link":"","permalink":"http://j2go.github.io/2016/11/04/2016-11-05-go-sparse/","excerpt":"","text":"使用 Docker 的我们都知道一个磁盘资源分配的问题，要么使用 devicemapper 设定一个固定大小，不过一旦确定就不可改，要么就没有限制，一个 container 就可能用尽整个磁盘空间。因为我们 WEDIDE 使用 Docker 运行大量服务，在调研了好几种磁盘分配方式后发现使用稀疏文件创建文件系统再挂载是一个很好的方案。 什么是稀疏文件?我们都知道计算机文件是存储在磁盘上的，都一个大小属性，让用户可以查询文件大小，但是并不是所有文件显示的大小就是真实的文件大小。一般情况下文件大小是真实所占磁盘的大小，但是有一类文件里有很多“空洞”，呈现的结果就是文件的大小属性值很大但真实占的磁盘空间很小。1234root@dev-d:/data/image# du -h file_trun.img 0 file_trun.imgroot@dev-d:/data/image# ls -lh file_trun.img -rw-r--r-- 1 root root 100M Sep 12 16:00 file_trun.img du 命令计算的是文件真实所占磁盘空间大小，ls 命令读取的是文件记录信息中的文件大小，这里就可以看到文件大小信息并不一定是文件真实大小。至于这种情况是怎么发生的，可以先看一下 UNIX 的文件系统组成： 图片 更细节的看 i 节点和数据块时大概是下面这样 图片 i 节点包含了文件有关的所有信息：文件类型、文件访问权限位、文件长度和指向文件数据块的的指针等。UNIX 系统调用的文件信息 stat 结构大多信息就取自 i 节点。当一个文件 i 节点中 只存储磁盘空间的 block 号，数据为空，而且并不占用物理磁盘 block 号时就形成了这样的稀疏文件，在写数据的时候才分配真正的磁盘空间。当然，是否支持这样的行为需要文件系统支持。 稀疏文件的作用 快速创建大文件 限制文件的最终大小 提高文件系统空间利用率 可创建虚拟文件系统 稀疏文件在虚拟磁盘和创建虚拟机时用的最多，使用一个文件即可在其中创建一个文件系统，在真正需要的时候才为其分配空间，提高了文件系统的利用率，还能与现有的文件系统隔离。 在使用 docker 的场景为了限制容器的磁盘使用，使用稀疏文件创建的文件系统是一个非常好的方案。 在 WEB-IDE Terminal 为每个项目提供独立的工作空间背后，正是使用了这种文件系统，既提高了文件系统利用率，又能为不同需要的用户提供不同空间大小。 Linux 下创建稀疏文件(以下示例运行环境均在 ubuntu14.04 下) 一种方式是使用 truncate 命令。12345root@dev-d:/data/image# truncate -s 100M file_trun.imgroot@dev-d:/data/image# du -h file_trun.img 0 file_trun.imgroot@dev-d:/data/image# ll -h file_trun.img -rw-r--r-- 1 root root 100M Sep 12 16:00 file_trun.img truncate 命令是将文件缩减或扩展至指定大小，-s 参数是指定大小。 第二种方式是使用 dd 命令。12345678910root@dev-d:/data/image# dd of=file-dd bs=1M seek=200 count=00+0 records in0+0 records out0 bytes (0 B) copied, 0.000419977 s, 0.0 kB/sdrwxr-xr-x 2 root root 4.0K Sep 12 16:02 ./drwxrwxr-x 5 vagrant vagrant 4.0K Sep 12 15:59 ../-rw-r--r-- 1 root root 200M Sep 12 16:02 file-dd-rw-r--r-- 1 root root 100M Sep 12 16:00 file_trun.imgroot@dev-d:/data/image# du -h file-dd0 file-dd dd 命令一般用于指定大小的拷贝文件，在拷贝的同时进行指定转换。of 参数是输出文件位置，bs 是块大小，seek 指定从文件开头跳过的块数量，count 指定要拷贝的数量，所以在不拷贝真实文件全部跳过时就生成了我们需要的空稀疏文件。另外还可以使用以下方式达到同样目的,1root@dev-d:/data/image# dd if=/dev/null of=file-dd bs=1M seek=200 if参数是输入文件位置，使用 null 来填充数据块指针，表现为不指向任何数据块。 稀疏文件使用注意一般情况下linux可直接用 cp 命令拷贝稀疏文件而不展开，12345678910root@dev-d:/data/image# cp file-dd file-dd2.imgroot@dev-d:/data/image# lltotal 8drwxr-xr-x 2 root root 4096 Sep 12 16:06 ./drwxrwxr-x 5 vagrant vagrant 4096 Sep 12 15:59 ../-rw-r--r-- 1 root root 209715200 Sep 12 16:02 file-dd-rw-r--r-- 1 root root 209715200 Sep 12 16:06 file-dd2.img-rw-r--r-- 1 root root 104857600 Sep 12 16:00 file_trun.imgroot@dev-d:/data/image# du -h file-dd2.img 0 file-dd2.img 但是有些系统 比如 FreeBSD 是不支持的，cp 操作会展开文件，“空洞”的地方全部用 0 填充，导致速度很慢，而且这也不是我们所预期的行为。cp 命令有一个参数 –sparse 提供支持, 命令说明中如下解释: By default, sparse SOURCE files are detected by a crude heuristic and the corresponding DEST file is made sparse as well. That is the behavior selected by –sparse=auto. Specify –sparse=always to create a sparse DEST file whenever the SOURCE file contains a long enough sequence of zero bytes. Use –sparse=never to inhibit creation of sparse files. 意思就是 默认–sparse=auto 会判断文件类型，拷贝结果与源文件一致; –sparse=always时总是会创建稀疏文件; –sparse=never 时总是会展开稀疏文件. Golang 操作稀疏文件判断文件是否是稀疏文件由上面的原理可知道稀疏文件的大小和真实的大小是不一致的，所以只要能判断真实的大小 小于文件信息中的大小就知道这个文件是稀疏文件。golang 实现代码如下：1234567891011121314151617181920212223242526272829func IsSparseFile(paht string) (bool, error)&#123; allocated, taken, err := FileSize(path) if err != nil &#123; return false, err &#125; return allocated &gt; taken, nil&#125;//返回值有三个，第一个是文件大小，第二个是真是文件大小，第三个值是错误func FileSize(path string) (allocated int64, taken int64, err error) &#123; s := syscall.Stat_t&#123;&#125; err = syscall.Stat(path, &amp;s) if err != nil &#123; return 0, 0, err &#125; blockSize, err := FSBlockSize(path) if err != nil &#123; return 0, 0, err &#125; return s.Size, s.Blocks * int64(blockSize), nil&#125;// 返回真实的块大小func FSBlockSize(path string) (blockSize int, err error) &#123; s := syscall.Statfs_t&#123;&#125; err = syscall.Statfs(path, &amp;s) if err != nil &#123; return 0, err &#125; return int(s.Bsize), nil&#125; 创建稀疏文件使用原生 api 方式：1234567891011121314151617func CreateSparseFile() &#123; if f, err := os.Create(\"go-trun.img\"); err != nil &#123; log.Fatal(\"create error\") &#125; else &#123; f.Close() &#125; err := os.Truncate(\"go-trun.img\", 100*1024*1024) if err != nil &#123; log.Fatal(err) &#125; log.Println(\"created.\") f, err := os.Stat(\"go-trun.img\") if err != nil &#123; log.Fatal(\"stat error:\", err) &#125; log.Println(\"size:\", f.Size, \"ok\")&#125; 创建一个空文件，然后用系统调用将文件扩展至指定大小。这种方法还有另一个用途，扩展现有稀疏文件的大小，正确性验证过程附在文末。 第二种种方式是调用系统 dd 命令来创建,123456789101112131415func CreateSparseFile(path string, size int) error &#123; seek := fmt.Sprintf(\"seek=%d\", size*1024) out, err := exec.Command(\"dd\", \"if=/dev/null\", \"of=\"+path, \"bs=1M\", seek).CombinedOutput() if err != nil &#123; return err &#125; if exitErr, ok := err.(*exec.ExitError); ok &#123; command := fmt.Sprintf(\"dd if=/dev/null of=%s bs=1M %s\", path, seek) status := exitErr.Sys().(syscall.WaitStatus) exitCode := status.ExitStatus() return fmt.Errorf(\"command %q exits with %d: %s\", command, exitCode, out) &#125; return nil&#125; 此种方法属于调用 shell 执行操作，这种方式还可用于执行任何 shell 命令。 稀疏文件的拷贝最简单的方法和 2.2 中第二种方法一样，调用 cp 命令来拷贝，这种方式简单有效。 另外使用 go sdk 也能做到，不过比较麻烦一些。下面的方式是直接使用 sdk 的 io.Copy() 拷贝：1234567vagrant@ide-a:~/test$ ll dd2.img-rw-rw-r-- 1 vagrant vagrant 524288000 Dec 27 17:07 dd2.imgvagrant@ide-a:~/test$ du dd2.img4504 dd2.imgvagrant@ide-a:~/test$ go run t.go2016/12/28 17:21:04 write bytes: 524,288,0002016/12/28 17:21:04 cost time: 1,715,998,834 ns 这效率实在没法看，这才 500M 的文件，线上的 img 文件动辄几个 G，如果需要迁移使用这种方式猴年马月也完成不了。所以还是要从源头入手，要跳过无效的文件内容，只拷贝有效内容。有幸已经有人做过这个事情了，在 github 上的一个项目 sparsed 使用 sdk 的 bufio 完成了这个事情，测试代码：12345678910111213package mainimport ( \"github.com/mkorenkov/sparsed\" \"log\" \"time\")func main() &#123; start := time.Now() sparsed.CopyFile(\"dd2.img\", \"dd2.img.spec\") end := time.Now() log.Printf(\"cost time: %d ns\", end.UnixNano()-start.UnixNano())&#125; 测试结果:12vagrant@ide-a:~$ ./test2016/12/28 17:42:12 cost time: 10,628 ns 在只拷贝有效内容的情况下只用了 0.01 微秒，效果立竿见影。当然了，这是在真实磁盘空间占用比较小的情况下，实际环境下还是得看占用的空间大小和磁盘速度。 SparseFileWiki golang系统调用扩容稀疏文件验证过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748vagrant@ide-a:~/test$ mkfs.ext4 dd2.imgmke2fs 1.42.9 (4-Feb-2014)dd2.img is not a block special device.Proceed anyway? (y,n) yDiscarding device blocks: doneFilesystem label=OS type: LinuxBlock size=1024 (log=0)Fragment size=1024 (log=0)Stride=0 blocks, Stripe width=0 blocks64000 inodes, 256000 blocks12800 blocks (5.00%) reserved for the super userFirst data block=1Maximum filesystem blocks=6737100832 block groups8192 blocks per group, 8192 fragments per group2000 inodes per groupSuperblock backups stored on blocks: 8193, 24577, 40961, 57345, 73729, 204801, 221185Allocating group tables: doneWriting inode tables: doneCreating journal (4096 blocks): doneWriting superblocks and filesystem accounting information: donevagrant@ide-a:~/test$ du dd2.img4496 dd2.imgvagrant@ide-a:~/test$ sudo mount dd2.img dd2test/vagrant@ide-a:~/test/dd2test$ sudo vim t.txtvagrant@ide-a:~/test/dd2test$ cat t.txttestvagrant@ide-a:~/test$ sudo umount dd2.imgvagrant@ide-a:~/test$ ls -lhtotal 5.2M-rw-rw-r-- 1 vagrant vagrant 200M Dec 27 16:51 dd.img-rw-rw-r-- 1 vagrant vagrant 250M Dec 27 17:04 dd2.imgdrwxrwxr-x 2 vagrant vagrant 4.0K Dec 27 16:58 dd2test-rw-rw-r-- 1 vagrant vagrant 100M Dec 27 16:51 go-trun.img-rw-r--r-- 1 vagrant vagrant 1.2K Dec 27 17:05 test.govagrant@ide-a:~/test$ go run test.go2016/12/23 00:36:23 adjust to 500 M succvagrant@ide-a:~/test$ sudo mount dd2.img dd2testvagrant@ide-a:~/test$ cat dd2test/lost+found/ t.txtvagrant@ide-a:~/test$ cat dd2test/lost+found/ t.txtvagrant@ide-a:~/test$ cat dd2test/t.txttest","categories":[{"name":"Golang","slug":"Golang","permalink":"http://j2go.github.io/categories/Golang/"}],"tags":[{"name":"文件","slug":"文件","permalink":"http://j2go.github.io/tags/文件/"}]},{"title":"Docker Swarm 试用","slug":"2016-10-15-docker-swarm","date":"2016-10-14T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/10/14/2016-10-15-docker-swarm/","link":"","permalink":"http://j2go.github.io/2016/10/14/2016-10-15-docker-swarm/","excerpt":"","text":"环境 系统 Ubuntu 14.04, Docker version: 1.12 创建 swarm节点操作机器 a12345678910111213141516root@ide-a:~# docker swarm initError response from daemon: could not choose an IP address to advertise since this system has multiple addresses on different interfaces (10.211.55.16 on eth0 and 192.168.3.10 on eth1) - specify one with --advertise-addrroot@ide-a:~# docker swarm init --advertise-addr 192.168.3.10Swarm initialized: current node (e6q1r4qw1jatxvqk056fu6502) is now a manager.To add a worker to this swarm, run the following command: docker swarm join \\ --token SWMTKN-1-6cvv0fm296x7c686a8ojxie33ob502hjdxickcj7ycitwqd2ej-bch1g33glv0ktox9qg0q7qshj \\ 192.168.3.10:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions.root@ide-a:~# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUSe6q1r4qw1jatxvqk056fu6502 * ide-a Ready Active Leader 机器 b1234vagrant@ide-b:~$ docker swarm join \\&gt; --token SWMTKN-1-6cvv0fm296x7c686a8ojxie33ob502hjdxickcj7ycitwqd2ej-bch1g33glv0ktox9qg0q7qshj \\&gt; 192.168.3.10:2377This node joined a swarm as a worker. 同样添加一个机器 c 然后在机器 a 上看12345vagrant@ide-a:~$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS2mcmsgvu4nvgymaqaexnevxn3 ide-b Ready Active6arg09xduwb65r6zaof61tjzk ide-c Ready Activee6q1r4qw1jatxvqk056fu6502 * ide-a Ready Active Leader 如果关闭一个机器12345vagrant@ide-a:~$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS2mcmsgvu4nvgymaqaexnevxn3 ide-b Down Active6arg09xduwb65r6zaof61tjzk ide-c Ready Activee6q1r4qw1jatxvqk056fu6502 * ide-a Ready Active Leader 把一个结点变成 manager1234567vagrant@ide-a:~$ docker node promote 2mcmsgvu4nvgymaqaexnevxn3Node 2mcmsgvu4nvgymaqaexnevxn3 promoted to a manager in the swarm.ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS2mcmsgvu4nvgymaqaexnevxn3 ide-b Ready Active Reachable6arg09xduwb65r6zaof61tjzk ide-c Ready Activee6q1r4qw1jatxvqk056fu6502 * ide-a Ready Active Leader 模拟 a 机器宕机 但是 b 机器始终没有变成 manager12vagrant@ide-b:~$ docker node lsError response from daemon: rpc error: code = 2 desc = raft: no elected cluster leader 当重启 a 机器节点时 b 就成 Leader 了1234ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS2mcmsgvu4nvgymaqaexnevxn3 * ide-b Ready Active Leader6arg09xduwb65r6zaof61tjzk ide-c Ready Activee6q1r4qw1jatxvqk056fu6502 ide-a Ready Active Reachable 由此怀疑内部的 raft 算法是一定要收到回复才能确定自己是 Leader 把 c 也设一下 manager 然后关闭 b 看看12345678910111213vagrant@ide-a:~$ docker node promote ide-cNode ide-c promoted to a manager in the swarm.vagrant@ide-a:~$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS2mcmsgvu4nvgymaqaexnevxn3 ide-b Ready Active Leader6arg09xduwb65r6zaof61tjzk ide-c Ready Active Reachablee6q1r4qw1jatxvqk056fu6502 * ide-a Ready Active Reachablevagrant@ide-a:~$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS2mcmsgvu4nvgymaqaexnevxn3 ide-b Unknown Active Unreachable6arg09xduwb65r6zaof61tjzk ide-c Ready Active Reachablee6q1r4qw1jatxvqk056fu6502 * ide-a Ready Active Leader ok，这下就是无缝切换了。 在swarm 上运行一个应用1234567891011121314151617181920212223242526vagrant@ide-a:~$ docker service create --replicas 1 --name helloworld alpine ping docker.comexzsbuclde7fmxr74days2v7hvagrant@ide-a:~$ docker node ps ide-aID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORvagrant@ide-a:~$ docker node ps ide-bID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORcvsbavho7pqvabhe1pk4r5zik helloworld.1 alpine ide-b Running Preparing 13 seconds agovagrant@ide-a:~$ docker node ps ide-cID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORvagrant@ide-a:~$ docker service lsID NAME REPLICAS IMAGE COMMANDexzsbuclde7f helloworld 1/1 alpine ping docker.comvagrant@ide-a:~$ docker service inspect --pretty exzsbuclde7fID: exzsbuclde7fmxr74days2v7hName: helloworldMode: ReplicatedReplicas: 1Placement:UpdateConfig:Parallelism: 1On failure: pauseContainerSpec:Image: alpineArgs: ping docker.comResources: 查看在哪台机器上123vagrant@ide-a:~$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORcvsbavho7pqvabhe1pk4r5zik helloworld.1 alpine ide-b Running Running 5 minutes ago 扩展5个实例123456789vagrant@ide-b:~$ docker service scale helloworld=5helloworld scaled to 5vagrant@ide-b:~$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORcvsbavho7pqvabhe1pk4r5zik helloworld.1 alpine ide-b Running Running 15 minutes ago3z6yoie0qs5o388win82g9s3i helloworld.2 alpine ide-c Running Preparing 16 seconds agodbltvky8b1omkhfsgetudfzix helloworld.3 alpine ide-b Running Preparing 15 seconds ago0zz270134yk761b61btj2u7vd helloworld.4 alpine ide-a Running Preparing 16 seconds ago7cqitdly74zcrf6vy4pzhbw2u helloworld.5 alpine ide-c Running Preparing 16 seconds ago 删除 service1234vagrant@ide-b:~$ docker service rm helloworldhelloworldvagrant@ide-b:~$ docker service ps helloworldError: No such service: helloworld 检验 swarm 是否保证实例个数开启3个实例12345678vagrant@ide-b:~$ docker service create --replicas 3 --name helloworld alpine ping docker.comDt81b618tz8yu8g5opw5990divagrant@ide-b:~$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR6drq6vomc15ils31ymr6lhgqk helloworld.1 alpine ide-a Running Preparing 30 seconds ago0j3m7oqf2cxxv1dof7q2fbhzw helloworld.2 alpine ide-c Running Running 23 seconds ago7khhv039gw3a9h4p3qaorbkg3 helloworld.3 alpine ide-b Running Running 21 seconds ago 关闭 c 机器123456vagrant@ide-b:~$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR6drq6vomc15ils31ymr6lhgqk helloworld.1 alpine ide-a Running Running 53 seconds ago85d8d1tuus0qmikwtv0qi6ulo helloworld.2 alpine ide-b Running Preparing 7 seconds ago0j3m7oqf2cxxv1dof7q2fbhzw \\_ helloworld.2 alpine ide-c Shutdown Running about a minute ago7khhv039gw3a9h4p3qaorbkg3 helloworld.3 alpine ide-b Running Running about a minute ago OK，确实有3个实例在，那么再开启 c 机器1234567891011vagrant@ide-b:~$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS2mcmsgvu4nvgymaqaexnevxn3 * ide-b Ready Active Reachable6arg09xduwb65r6zaof61tjzk ide-c Ready Activee6q1r4qw1jatxvqk056fu6502 ide-a Ready Active Leadervagrant@ide-b:~$ docker service ps helloworldID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR6drq6vomc15ils31ymr6lhgqk helloworld.1 alpine ide-a Running Running 2 minutes ago85d8d1tuus0qmikwtv0qi6ulo helloworld.2 alpine ide-b Running Running about a minute ago0j3m7oqf2cxxv1dof7q2fbhzw \\_ helloworld.2 alpine ide-c Shutdown Complete 19 seconds ago7khhv039gw3a9h4p3qaorbkg3 helloworld.3 alpine ide-b Running Running 3 minutes ago 没有变化，在 c 上强行开起来 ps 结果也没发生变化删除服务1234vagrant@ide-b:~$ docker service rm helloworldhelloworldvagrant@ide-b:~$ docker service ps helloworldError: No such service: helloworld c 机器上依然有这个 不按规则 的 container存在123vagrant@ide-c:/data/coding-ide-home$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESffe29f05f2e7 alpine:latest &quot;ping docker.com&quot; 9 minutes ago Up About a minute helloworld.2.0j3m7oqf2cxxv1dof7q2fbhzw 测试过如果没有人为启动起来在用 service rm 指令删除后该异常 container 也退出了 关闭一个节点但是该节点的 docker deman没有停掉准确的说是停用一个节点，设置了一个状态1$ docker node update --availability drain ide-c 复活1$ docker node update --availability active ide-c 测试滚动更新创建一个滚动更新的服务1234567vagrant@ide-a:~$ docker service create --replicas 3 --name redis --update-delay 10s redis:3.0.6c1cieiareqz8l43ckr8ekstc9vagrant@ide-a:~$ docker service ps redisID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORdv0bqyp5j8rt2qhdb67vk1ux6 redis.1 redis:3.0.6 ide-a Running Preparing 11 seconds agoednp70fzj2nocae2gismqgx3c redis.2 redis:3.0.6 ide-c Running Preparing 11 seconds ago1m0fnh3qhkj1rfpufdkmn3cqd redis.3 redis:3.0.6 ide-b Running Preparing 13 seconds ago 作用是神马？为了多实例的平滑升级123456vagrant@ide-a:~$ docker service ps redisID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORdv0bqyp5j8rt2qhdb67vk1ux6 redis.1 redis:3.0.6 ide-a Running Preparing 4 minutes agoednp70fzj2nocae2gismqgx3c redis.2 redis:3.0.6 ide-c Running Running 3 minutes ago0rgbjgr5cf8gz7cyt0hhhgin4 redis.3 redis:3.0.7 ide-a Running Preparing about a minute ago1m0fnh3qhkj1rfpufdkmn3cqd \\_ redis.3 redis:3.0.6 ide-b Shutdown Shutdown about a minute ago 不过好像测试过程中有点问题，只升级了一个节点就停止了 Swarm 集群管理 创建对外服务的实例1234567vagrant@ide-a:~$ docker service create --name my_web --replicas 3 --publish 2345:80 nginx6wud0bt1qbs6upptvddxvkc4kvagrant@ide-a:~$ docker service ps my_webID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERRORcf5co7yx4x79cn2ruirothgi1 my_web.1 nginx ide-a Running Preparing 4 seconds ago3ibjg29g7nq6j1a2533neerb5 my_web.2 nginx ide-c Running Preparing 4 seconds ago096muixt5lmd5c0oedrwkzg9y my_web.3 nginx ide-b Running Preparing 5 seconds ago 能访问的地址是最开始设置的 –advertise-addr 的地址1vagrant@ide-a:~$ curl http://192.168.3.10:2345 一个问题: 对外有一个 端口 提供服务，如果这个主 IP 的节点挂掉了呢？ 测试显示绑定一个端口对外服务，访问集群中所有 ip +该端口 均能得到结果 能否在指定节点上创建 container？有一种方式在每个可用节点上运行一个 service1docker service create --name myservice --mode global alpine top 实验结果表明 swarm 都是负载均衡的，即使使用 global 模式，访问其中一个指定 ip 的请求也会均衡转发到各个节点中去","categories":[{"name":"Linux","slug":"Linux","permalink":"http://j2go.github.io/categories/Linux/"}],"tags":[{"name":"DockerSwarm","slug":"DockerSwarm","permalink":"http://j2go.github.io/tags/DockerSwarm/"}]},{"title":"Centos6.5 搭建 nexus + maven","slug":"2016-04-29-nexus-maven","date":"2016-04-28T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/04/28/2016-04-29-nexus-maven/","link":"","permalink":"http://j2go.github.io/2016/04/28/2016-04-29-nexus-maven/","excerpt":"","text":"安装MAVEN #wget http://mirror.cc.columbia.edu/pub/software/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz#tar -zxvf apache-maven-3.3.9-bin.tar.gz#mkdir /usr/local/maven#mv -rf apache-maven-3.3.9/* /usr/local/maven/ 修改环境配置 # vi /etc/profile 加入 export M2_HOME=/usr/local/mavenexport PATH=${M2_HOME}/bin:${PATH}# source /etc/profile 检查结果 # mvn -vApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)Maven home: /usr/local/mavenJava version: 1.7.0_79, vendor: Oracle CorporationJava home: /usr/java/jdk1.7.0_79/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: “linux”, version: “2.6.32-431.el6.x86_64”, arch: “amd64”, family: “unix” 安装nexus需要翻墙才能下nexus-2.13.0-01-bundle.tar.gz 然后解压 #tar -zxvf nexus-2.13.0-01-bundle.tar.gz 产生如下两个目录 drwxr-xr-x 8 1001 1001 4096 4月 28 16:06 nexus-2.13.0-01drwxr-xr-x 3 1001 1001 4096 4月 12 22:21 sonatype-work 直接去运行会报错 # nexus-2.13.0-01/bin/nexus startStarting Nexus OSS…Failed to start Nexus OSS. stackoverflow上找到了答案，不能用root用户运行，新建并切换用户之… 还要切换目录owner #chown -R rd:rd nexus-2.13.0-01#chown -R sonatype-work 接下来就可以运行了 #nexus start 打开 http://localhost:8081/nexus 即可看到nexus的管理页面 _默认账户密码_admin admin123","categories":[{"name":"Linux","slug":"Linux","permalink":"http://j2go.github.io/categories/Linux/"}],"tags":[{"name":"nexus","slug":"nexus","permalink":"http://j2go.github.io/tags/nexus/"}]},{"title":"nginx配置缓存","slug":"2016-04-28-nginx-cache","date":"2016-04-27T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/04/27/2016-04-28-nginx-cache/","link":"","permalink":"http://j2go.github.io/2016/04/27/2016-04-28-nginx-cache/","excerpt":"","text":"配置记录笔记123456789101112131415161718192021222324252627http&#123; ....... proxy_connect_timeout 5; proxy_read_timeout 60; proxy_send_timeout 5; proxy_buffer_size 16k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; proxy_temp_path /tmp/proxy_temp_dir; proxy_cache_path /tmp/proxy_cache_dir levels=1:2 keys_zone=cache_one:200m inactive=1d max_size=30g; ...... server&#123; ...... location /static/ &#123; ...... proxy_cache cache_one; proxy_cache_valid 200 302 1h; expires 10d; ...... &#125; ...... &#125; ......&#125;","categories":[{"name":"Linux","slug":"Linux","permalink":"http://j2go.github.io/categories/Linux/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://j2go.github.io/tags/Nginx/"}]},{"title":"初试 Netty4.1","slug":"2016-04-15-netty4-1","date":"2016-04-14T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/04/14/2016-04-15-netty4-1/","link":"","permalink":"http://j2go.github.io/2016/04/14/2016-04-15-netty4-1/","excerpt":"","text":"之前通过以前公司的框架和github上的一个开源框架封装过一个东东，还根据自己的思考完善了下通讯协议，看这里。 不过呢之前哪个是 netty3.x的，而且还是 jboss的包，现在都是 io.netty了，以前一直是一知半解的状态，没有深入研究过，所以现在就循序渐进好好搞一搞。 直接上最新的 netty4.1CR7 jdk812345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.0.CR7&lt;/version&gt;&lt;/dependency&gt; 首先看一下如何跑起来。按照官方 Guide 这么写了1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TGServer &#123; private static final Logger log = LoggerFactory.getLogger(TGServer.class); final int port; public TGServer(int port) &#123; this.port = port; &#125; public void start() &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); // (1) EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); // (2) b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) // (3) .childHandler(new GameChannelInitializer()) .option(ChannelOption.SO_BACKLOG, 128) // (5) .childOption(ChannelOption.SO_KEEPALIVE, true); // (6) // Bind and start to accept incoming connections. ChannelFuture f = b.bind(port).sync(); // (7) // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. log.info(&quot;listen on &quot; + port + &quot;success&quot;); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) &#123; new TGServer(8901).start(); &#125;&#125; 关键地方在18行 .childHandler(new GameChannelInitializer())12345public class GameChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt;&#123; protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(new StringDecoder()).addLast(new StringEncoder()).addLast(new GameServerHandler()); &#125;&#125; 这里我试过把几个的顺序换一下，结果就不行了，把new GameServerHandler()换到中间会出现客户端无法收到服务器发送消息的情况然后是试试 GameServerHandler()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class GameServerHandler extends ChannelInboundHandlerAdapter&#123; private static final Logger log = LoggerFactory.getLogger(GameServerHandler.class); @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;=============== channelRegistered ==============&quot;); log.debug(&quot;---&quot; + ctx.toString()); &#125; @Override public void channelUnregistered(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;=============== channelUnregistered ==============&quot;); log.debug(&quot;---&quot; + ctx.toString()); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; log.debug(&quot;=============== channelRead ==============&quot;); log.debug(&quot;---&quot; + ctx.toString()); log.debug(&quot;---&quot; + msg.toString());// if (msg instanceof String) &#123;// log.debug(&quot;String:&quot; + msg);// &#125; ctx.writeAndFlush(&quot;server recv: &quot; + msg); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;=============== channelReadComplete ==============&quot;); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; log.debug(&quot;=============== exceptionCaught ==============&quot;);// log.debug(&quot;excption&quot;, cause); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;=============== channelActive ==============&quot;); log.debug(&quot;---&quot; + ctx.toString()); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;=============== channelActive ==============&quot;); log.debug(&quot;---&quot; + ctx.toString()); &#125;&#125; 然后看输出就知道数据处理的流程的，这里我没用 Netty 的客户端，我用 golang 来tcp连接测试执行日志如下一目了然123456789101112131415161718192021222324252627282930313211:33:41.717 - === channelRegistered ===11:33:41.724 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 - R:/0:0:0:0:0:0:0:1:51145])11:33:41.724 - === channelActive ===11:33:41.724 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 - R:/0:0:0:0:0:0:0:1:51145])11:33:46.312 - -Dio.netty.recycler.maxCapacity: 26214411:33:46.319 - -Dio.netty.buffer.bytebuf.checkAccessible: true11:33:46.329 - === channelRead ===11:33:46.329 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 - R:/0:0:0:0:0:0:0:1:51145])11:33:46.329 - ---AA 接入11:33:46.330 - === channelReadComplete ===11:33:51.162 - === channelRead ===11:33:51.162 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 - R:/0:0:0:0:0:0:0:1:51145])11:33:51.162 - ---AA : 你好11:33:51.162 - === channelReadComplete ===11:33:54.850 - === channelRead ===11:33:54.850 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 - R:/0:0:0:0:0:0:0:1:51145])11:33:54.850 - ---AA : good11:33:54.850 - === channelReadComplete ===11:34:00.016 - === channelRead ===11:34:00.016 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 - R:/0:0:0:0:0:0:0:1:51145])11:34:00.016 - ---AA 退出了 11:34:00.016 - === channelReadComplete ===11:34:00.018 - === channelReadComplete ===11:34:00.018 - === exceptionCaught ===11:34:00.019 - === channelActive ===11:34:00.019 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 ! R:/0:0:0:0:0:0:0:1:51145])11:34:00.019 - === channelUnregistered ===11:34:00.019 - ---ChannelHandlerContext(GameServerHandler#0, [id: 0xbda05939, L:/0:0:0:0:0:0:0:1:8901 ! R:/0:0:0:0:0:0:0:1:51145])","categories":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/categories/Java/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"http://j2go.github.io/tags/Netty/"}]},{"title":"数据排序——排行榜","slug":"2016-05-15-ranklist","date":"2016-04-14T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/04/14/2016-05-15-ranklist/","link":"","permalink":"http://j2go.github.io/2016/04/14/2016-05-15-ranklist/","excerpt":"","text":"问题： 1w 10w 100w 数据找出前10 100 1000个，怎么弄效率较高? 全排序冒泡12345678910111213141516public void sort(int []a, boolean isUp)&#123; for (int i =0; i &lt; a.length - 1; i++) &#123; for (int j=0; j &lt; a.length - i - 1; j++)&#123; if ( isUp &amp;&amp; a[j] &lt; a[j+1]) &#123; int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; &#125; else if( !isUp &amp;&amp; a[j] &gt; a[j+1]) &#123; int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; &#125; &#125; &#125; &#125; 快排1234567891011121314151617public void qsort(int[] a, int lo, int hi) &#123; if ( lo &gt;= hi) return; int left = lo, right = hi; int mid = a[(left+right)/2]; while(left &lt; right) &#123; while(mid &lt; a[left]) left++; while(mid &gt; a[right]) right--; if (left &lt; right) &#123; int temp = a[left]; a[left] = a[right]; a[right] = temp; &#125; &#125; qsort(a, lo, right - 1); qsort(a, left + 1, hi); &#125; 固定大小列表的插入排序123456789101112131415161718192021//链表长度final static int DEFAULT_SHOW_SIZE = 10;static void insert(LinkedList&lt;Integer&gt; list, int x)&#123; if (list.size() &gt; 10 &amp;&amp; x &lt; list.getLast()) &#123; return; &#125; if (list.size() == 0) &#123; list.add(x); return; &#125; int size = DEFAULT_SHOW_SIZE &gt; list.size() ? list.size(): DEFAULT_SHOW_SIZE; for (int i = 0; i &lt; size; i++) &#123; if (x &gt;= list.get(i)) &#123; list.add(i, x); if (list.size() &gt; DEFAULT_SHOW_SIZE) &#123; list.removeLast(); &#125; return; &#125; &#125; &#125; 当然还有其他很多方式，不过个人拙见有限 测试数组大小 1000 前10个 冒泡: 11ms快排: 1ms链表: 4ms 数组大小 1W 前100个 冒泡: 198ms快排: 4ms链表: 9ms 冒泡: 310ms快排: 11ms链表: 6ms 冒泡: 290ms快排: 4ms链表: 5ms 多次测试后发现，快排真的不稳定 数组大小 1W 前500个 链表: 286ms冒泡: 239ms快排: 6ms 链表: 86ms冒泡: 246ms快排: 7ms 链表: 126ms冒泡: 282ms快排: 3ms 链表果不其然效率下来了，插入排序效率也还是有局限，可以用二分查找优化下，效率肯定提升极大 数组大小 10W 前100个 链表: 15ms冒泡: 20643ms快排: Failed 这里冒泡已经不能看了，然而快排直接就失败了。。。难道因为递归的原因，可是也没有 StackOverFlow 错误抛出。。。数组大小换成3W 链表: 9ms冒泡: 2215ms快排: 依然跑不出结果。。。再来试 2W 链表: 11ms冒泡: 888ms快排: 15ms 2.5W 链表: 13ms冒泡: 1618ms快排: 7ms 2.8W 链表: 11ms冒泡: 1833ms快排: 11ms 2.9W又嗝屁了，看来是代码问题，卧槽.实际使用还是老实的用 jdk 的 Collections.sort吧 测试程序代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162public class SimpleSortTest &#123; final static Comparator&lt;Integer&gt; HIGH_COMPARATOR = new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1 - o2; &#125; &#125;; final static Comparator&lt;Integer&gt; LOW_COMPARATOR = new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2 - o1; &#125; &#125;; final static boolean UP_ORDER = true; final static boolean LOW_ORDER = false; public void sort(int []a, Comparator&lt;Integer&gt; comparator)&#123; for (int i =0; i &lt; a.length - 1; i++) &#123; for (int j=0;j &lt; a.length - i - 1; j++)&#123; if (comparator.compare(a[j], a[j+1]) &gt; 0) &#123; int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; &#125; &#125; &#125; &#125; public void sort(int []a, boolean isUp)&#123; for (int i =0; i &lt; a.length - 1; i++) &#123; for (int j=0; j &lt; a.length - i - 1; j++)&#123; //如果 isUp ture 升序 if ( isUp &amp;&amp; a[j] &lt; a[j+1]) &#123; int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; &#125; else if( !isUp &amp;&amp; a[j] &gt; a[j+1]) &#123; int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; &#125; &#125; &#125; &#125; public void qsort(int[] a, int lo, int hi) &#123; if ( lo &gt;= hi) return; int left = lo, right = hi; int mid = a[(left+right)/2]; while(left &lt; right) &#123; while(mid &lt; a[left]) left++; while(mid &gt; a[right]) right--; if (left &lt; right) &#123; int temp = a[left]; a[left] = a[right]; a[right] = temp; &#125; &#125; qsort(a, lo, right - 1); qsort(a, left + 1, hi); &#125; final static int TEST_LIST_SIZE = 10000; final static int DEFAULT_SHOW_SIZE = 500; public static void main(String[] args)&#123; int[] demo = generateRandomArray(); linkListTest(demo); orderTest(demo); qSortTest(demo); &#125; private static void qSortTest(int[] array) &#123; System.out.print(\"快排: \"); long start = System.currentTimeMillis(); int[] demo = new int[TEST_LIST_SIZE]; for (int i = 0; i &lt; array.length; i++) &#123; demo[i] = array[i]; &#125; new SimpleSort().qsort(demo, 0, demo.length - 1); long end = System.currentTimeMillis(); System.out.println((end - start) +\"ms\");// System.out.println();// for (int i = 0; i &lt; DEFAULT_SHOW_SIZE; i++) &#123;// System.out.println(demo[i]);// &#125;// System.out.println(); &#125; public static void orderTest(int[] array) &#123; System.out.print(\"冒泡: \"); long start = System.currentTimeMillis(); int[] demo = new int[TEST_LIST_SIZE]; for (int i = 0; i &lt; array.length; i++) &#123; demo[i] = array[i]; &#125; new SimpleSort().sort(demo, UP_ORDER); long end = System.currentTimeMillis(); System.out.println((end - start) + \"ms\");// System.out.println();// for (int i = 0; i &lt; DEFAULT_SHOW_SIZE; i++) &#123;// System.out.println(demo[i]);// &#125;// System.out.println(); &#125; public static void linkListTest(int[] array)&#123; System.out.print(\"链表: \"); long start = System.currentTimeMillis(); int[] demo2 = new int[TEST_LIST_SIZE]; for (int i = 0; i &lt; array.length; i++) &#123; demo2[i] = array[i]; &#125; LinkedList&lt;Integer&gt; linkList = new LinkedList&lt;&gt;(); for(int i: demo2) &#123; insert(linkList, i); &#125; long end = System.currentTimeMillis(); System.out.println((end - start) +\"ms\");// System.out.println();// linkList.forEach(System.out::println);// System.out.println(); &#125; static Random random = new Random(); public static int[] generateRandomArray() &#123; int[] demo = new int[TEST_LIST_SIZE]; for (int i = 0; i &lt; demo.length - 1; i++) &#123; demo[i] = random.nextInt(1000000000); &#125; return demo; &#125; static void insert(LinkedList&lt;Integer&gt; list, int x)&#123; if (list.size() &gt; 10 &amp;&amp; x &lt; list.getLast()) &#123; return; &#125; if (list.size() == 0) &#123; list.add(x); return; &#125; int size = DEFAULT_SHOW_SIZE &gt; list.size() ? list.size(): DEFAULT_SHOW_SIZE; for (int i = 0; i &lt; size; i++) &#123; if (x &gt;= list.get(i)) &#123; list.add(i, x); if (list.size() &gt; DEFAULT_SHOW_SIZE) &#123; list.removeLast(); &#125; return; &#125; &#125; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://j2go.github.io/categories/算法/"}],"tags":[]},{"title":"双向链表排序","slug":"2016-04-10-linkedlist-sort","date":"2016-04-09T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/04/09/2016-04-10-linkedlist-sort/","link":"","permalink":"http://j2go.github.io/2016/04/09/2016-04-10-linkedlist-sort/","excerpt":"","text":"问题：双向链表排序，时间复杂度不超过o(nlogn) ,最坏情况不能达到 n^2,空间复杂度不能超过 o(1) ? 想法：反正都是指针，直接从头遍历挨个插入排序，二叉树思路 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127import java.util.ArrayList;import java.util.List;public class LinkedListSort &#123; public static void main(String[] args) &#123; LinkedList list = new LinkedList(); list.add(6).add(16).add(26).add(14).add(9).add(34).add(23); sort(list); &#125; static void sort(LinkedList list) &#123; System.out.println(list); dealLinkedListToBintree(list); list = preorderBintree(list); System.out.println(list); &#125; static LinkedList preorderBintree(LinkedList list) &#123; LinkedList res = new LinkedList(); Node root = list.head; Node nodeTemp = root; List&lt;Node&gt; stack = new ArrayList&lt;&gt;(); while (nodeTemp != null || stack.size() &gt; 0) &#123; while (nodeTemp != null) &#123; stack.add(nodeTemp); nodeTemp = nodeTemp.prev; &#125; nodeTemp = stack.get(stack.size() - 1); stack.remove(stack.size() - 1); res.add(nodeTemp.value); nodeTemp = nodeTemp.next; &#125; return res; &#125; static void dealLinkedListToBintree(LinkedList list) &#123; Node root = list.head; Node nodeNext = root.next; Node nodeInsert = null, temp = null; root.next = null; while (nodeNext != null) &#123; nodeInsert = root; temp = nodeNext; nodeNext = nodeNext.next; while (true) &#123; if (temp.value &lt; nodeInsert.value) &#123; if (nodeInsert.prev == null) &#123; nodeInsert.prev = temp; temp.prev = null; temp.next = null; break; &#125; nodeInsert = nodeInsert.prev; &#125; else &#123; if (nodeInsert.next == null) &#123; nodeInsert.next = temp; temp.prev = null; temp.next = null; break; &#125; nodeInsert = nodeInsert.next; &#125; &#125; &#125; &#125;&#125;class Node &#123; int value; Node prev; Node next; public Node(int x) &#123; value = x; &#125; public Node(int x, Node p, Node n) &#123; value = x; prev = p; next = n; &#125; public String toString() &#123; return \"\" + value; &#125;&#125;class LinkedList &#123; Node head = null; int size = 0; public LinkedList add(int x) &#123; if (head == null) &#123; head = new Node(x, null, null); &#125; else &#123; Node temp = head; while (temp.next != null) &#123; temp = temp.next; &#125; temp.next = new Node(x, temp, null); &#125; size++; return this; &#125; public String toString() &#123; StringBuilder builder = new StringBuilder(); builder.append(size).append(\"[\"); Node temp = head; while (temp != null) &#123; builder.append(temp.value); temp = temp.next; if (temp != null) &#123; builder.append(\",\"); &#125; &#125; builder.append(\"]\"); return builder.toString(); &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://j2go.github.io/categories/算法/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://j2go.github.io/tags/排序/"}]},{"title":"Collections.sort 原理探究","slug":"2016-03-28-collection-sort","date":"2016-03-27T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2016/03/27/2016-03-28-collection-sort/","link":"","permalink":"http://j2go.github.io/2016/03/27/2016-03-28-collection-sort/","excerpt":"","text":"从代码的角度一步步深入，首先 12List&lt;String&gt; list = new ArrayList&lt;String&gt;();Collections.sort(list); 里面是这样1234@SuppressWarnings(\"unchecked\")public static &lt;T extends Comparable&lt;? super T&gt;&gt; void sort(List&lt;T&gt; list) &#123; list.sort(null);&#125; list 的泛型需要继承 Comparable 接口，否则需要使用1234@SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;)public static &lt;T&gt; void sort(List&lt;T&gt; list, Comparator&lt;? super T&gt; c) &#123; list.sort(c);&#125; list.sort 长这样12345678910 @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125; &#125; 转成数组 调用 Arrays.sort 排序 通过迭代器赋值回原来集合 然后关键来了，JDK 默认的的 sort 方法到底有多神奇呢？1234567891011121314151617 public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125; &#125; public static void sort(Object[] a) &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a); else ComparableTimSort.sort(a, 0, a.length, null, 0, 0); &#125; 再继续扒皮…1234private static void legacyMergeSort(Object[] a) &#123; Object[] aux = a.clone(); mergeSort(aux, a, 0, a.length, 0); &#125; 这里用了一个 clone() 方法，mergeSort 看来已经是归并排序了，是不是一会儿还得赋值回来？继续看…123456789101112131415161718192021222324252627282930313233343536373839404142@SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) private static void mergeSort(Object[] src, Object[] dest, int low, int high, int off) &#123; int length = high - low; //这里这个常量是7，长度小于7直接冒泡解决，比较的是 dest 数组 if (length &lt; INSERTIONSORT_THRESHOLD) &#123; for (int i=low; i&lt;high; i++) for (int j=i; j&gt;low &amp;&amp; ((Comparable) dest[j-1]).compareTo(dest[j])&gt;0; j--) swap(dest, j, j-1); return; &#125; // Recursively sort halves of dest into src int destLow = low; int destHigh = high; //从上面看下来off 是0，这里可以忽略 low += off; high += off; //新技能 Get int mid = (low + high) &gt;&gt;&gt; 1; mergeSort(dest, src, low, mid, -off); mergeSort(dest, src, mid, high, -off); // 如果列表已经有序, 只需要从 src 拷贝到 dest. 下面是优化过的拷贝算法 if (((Comparable)src[mid-1]).compareTo(src[mid]) &lt;= 0) &#123; System.arraycopy(src, low, dest, destLow, length); return; &#125; // 归并算法的最后，拷贝到 dest for(int i = destLow, p = low, q = mid; i &lt; destHigh; i++) &#123; if (q &gt;= high || p &lt; mid &amp;&amp; ((Comparable)src[p]).compareTo(src[q])&lt;=0) dest[i] = src[p++]; else dest[i] = src[q++]; &#125; &#125; 等等，好像什么地方漏了。。。。1TimSort.sort(a, 0, a.length, c, null, 0, 0); 看方法上的注释说这是自1.8开始后才使用的，尽可能使用给定的数据空间，为了提升性能而设计1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // Arrays of size 0 and 1 are always sorted // 如果数组长度小(这里是32), 使用0拷贝的\"mini-TimSort\"方式 if (nRemaining &lt; MIN_MERGE) &#123; int initRunLen = countRunAndMakeAscending(a, lo, hi, c); binarySort(a, lo, hi, lo + initRunLen, c); return; &#125; /** * March over the array once, left to right, finding natural runs, * extending short natural runs to minRun elements, and merging runs * to maintain stack invariant. */ TimSort&lt;T&gt; ts = new TimSort&lt;&gt;(a, c, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1; &#125; 擦，还得继续扒皮 binarySort123456789101112131415161718192021222324252627282930313233343536373839404142434445@SuppressWarnings(\"fallthrough\") private static &lt;T&gt; void binarySort(T[] a, int lo, int hi, int start, Comparator&lt;? super T&gt; c) &#123; assert lo &lt;= start &amp;&amp; start &lt;= hi; if (start == lo) start++; for ( ; start &lt; hi; start++) &#123; T pivot = a[start]; // Set left (and right) to the index where a[start] (pivot) belongs int left = lo; int right = start; assert left &lt;= right; /* * Invariants: * pivot &gt;= all in [lo, left). * pivot &lt; all in [right, start). */ while (left &lt; right) &#123; int mid = (left + right) &gt;&gt;&gt; 1; if (c.compare(pivot, a[mid]) &lt; 0) right = mid; else left = mid + 1; &#125; assert left == right; /* * The invariants still hold: pivot &gt;= all in [lo, left) and * pivot &lt; all in [left, start), so pivot belongs at left. Note * that if there are elements equal to pivot, left points to the * first slot after them -- that's why this sort is stable. * Slide elements over to make room for pivot. */ int n = start - left; // The number of elements to move // Switch is just an optimization for arraycopy in default case switch (n) &#123; case 2: a[left + 2] = a[left + 1]; case 1: a[left + 1] = a[left]; break; default: System.arraycopy(a, left, a, left + 1, n); &#125; a[left] = pivot; &#125; &#125; 这是一个二分的插入排序算法。然后研究了下下面这个函数，返回连续升序数据的数据量，如果前 n 个数据是连续降序排列的，翻转此序列，并返回 n 。为了防止最坏的情况12345678910111213141516171819private static &lt;T&gt; int countRunAndMakeAscending(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c) &#123; assert lo &lt; hi; int runHi = lo + 1; if (runHi == hi) return 1; // Find end of run, and reverse range if descending if (c.compare(a[runHi++], a[lo]) &lt; 0) &#123; // Descending while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &lt; 0) runHi++; reverseRange(a, lo, runHi); &#125; else &#123; // Ascending while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &gt;= 0) &#123; runHi++; &#125; &#125; return runHi - lo;&#125; TimeSort的逻辑还是挺复杂，这里引用一个 demo 的解释 http://blog.sina.com.cn/s/blog_8e6f1b330101h7fa.html Demo这一节用一个具体的例子来演示整个算法的演进过程：注意：为了演示方便，我将TimSort中的minRun直接设置为2，否则我不能用很小的数组演示。。。同时把MIN_MERGE也改成2（默认为32），这样避免直接进入binary sort。 初始数组为[7,5,1,2,6,8,10,12,4,3,9,11,13,15,16,14] =&gt; 寻找连续的降序或升序序列 (4.3.2) [1,5,7] [2,6,8,10,12,4,3,9,11,13,15,16,14] =&gt; 入栈 (4.3.4)当前的栈区块为[3]=&gt; 进入merge循环 (4.3.5)do not merge因为栈大小仅为1=&gt; 寻找连续的降序或升序序列 (4.3.2)[1,5,7] [2,6,8,10,12] [4,3,9,11,13,15,16,14]=&gt; 入栈 (4.3.4)当前的栈区块为[3, 5]=&gt; 进入merge循环 (4.3.5)merge因为runLen[0]&lt;=runLen[1]1) gallopRight：寻找run1的第一个元素应当插入run0中哪个位置（”2”应当插入”1”之后），然后就可以忽略之前run0的&gt;元素（都比run1的第一个元素小）2) gallopLeft：寻找run0的最后一个元素应当插入run1中哪个位置（”7”应当插入”8”之前），然后就可以忽略之后 run1 的元素（都比run0的最后一个元素大）这样需要排序的元素就仅剩下[5,7] [2,6]，然后进行mergeLow完成之后的结果：[1,2,5,6,7,8,10,12] [4,3,9,11,13,15,16,14]=&gt; 入栈 (4.3.4)当前的栈区块为[8]退出当前merge循环因为栈中的区块仅为1=&gt; 寻找连续的降序或升序序列 (4.3.2)[1,2,5,6,7,8,10,12] [3,4] [9,11,13,15,16,14]=&gt; 入栈 (4.3.4)当前的栈区块大小为[8,2]=&gt; 进入merge循环 (4.3.5)do not merge因为runLen[0]&gt;runLen[1]=&gt; 寻找连续的降序或升序序列 (4.3.2)[1,2,5,6,7,8,10,12] [3,4] [9,11,13,15,16] [14]=&gt; 入栈 (4.3.4)当前的栈区块为[8,2,5]=&gt;do not merege run1与run2因为不满足runLen[0]&lt;=runLen[1]+runLen[2]merge run2与run3因为runLen[1]&lt;=runLen[2]1) gallopRight：发现run1和run2就已经排好序完成之后的结果：[1,2,5,6,7,8,10,12] [3,4,9,11,13,15,16] [14]=&gt; 入栈 (4.3.4)当前入栈的区块大小为[8,7]退出merge循环因为runLen[0]&gt;runLen[1]=&gt; 寻找连续的降序或升序序列 (4.3.2)最后只剩下[14]这个元素：[1,2,5,6,7,8,10,12] [3,4,9,11,13,15,16] [14]=&gt; 入栈 (4.3.4)当前入栈的区块大小为[8,7,1]=&gt; 进入merge循环 (4.3.5)merge因为runLen[0]&lt;=runLen[1]+runLen[2]因为runLen[0]&gt;runLen[2]，所以将run1和run2先合并。（否则将run0和run1先合并）1) gallopRight &amp; 2) gallopLeft这样需要排序的元素剩下[13,15] [14]，然后进行mergeHigh完成之后的结果：[1,2,5,6,7,8,10,12] [3,4,9,11,13,14,15,16] 当前入栈的区块为[8,8]=&gt;继续merge因为runLen[0]&lt;=runLen[1]1) gallopRight &amp; 2) gallopLeft需要排序的元素剩下[5,6,7,8,10,12] [3,4,9,11]，然后进行mergeHigh完成之后的结果：[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16] 当前入栈的区块大小为[16]=&gt;不需要final merge因为当前栈大小为1=&gt;结束","categories":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://j2go.github.io/tags/Java/"}]},{"title":"Android 之 AsyncTask 学习","slug":"2015-03-04-android-asynctask","date":"2015-03-03T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2015/03/03/2015-03-04-android-asynctask/","link":"","permalink":"http://j2go.github.io/2015/03/03/2015-03-04-android-asynctask/","excerpt":"","text":"AsyncTask 就是一个封装过的后台任务类，顾名思义就是异步任务。 AsyncTask 直接继承于 Object 类，包位置为 android.os.AsyncTask. 要使用AsyncTask工作要提供三个泛型参数，并重载几个方法(至少重载一个)。 AsyncTask定义了三种泛型类型 Params，Progress和Result。 Params: 启动任务执行的输入参数，比如HTTP请求的URL。 Progress: 后台任务执行的百分比。 Result: 后台执行任务最终返回的结果，比如String。 要使用 AsyncTask 的同学都需要知道一个异步加载数据最少要重写以下这两个方法： doInBackground(Params…): 后台执行，比较耗时的操作都可以放在这里。注意这里不能直接操作UI。此方法在后台线程执行，完成任务的主要工作，通常需要较长的时间。在执行过程中可以调用publicProgress(Progress…)来更新任务的进度。 onPostExecute(Result): 相当于Handler 处理UI的方式，在这里面可以使用在doInBackground 得到的结果处理操作UI。 此方法在主线程执行，任务执行的结果作为此方法的参数返回 有必要的话还可重写以下这三个方法，但不是必须的： onProgressUpdate(Progress…): 可以使用进度条增加用户体验度。 此方法在主线程执行，用于显示任务执行的进度。 onPreExecute(): 这里是最终用户调用Excute时的接口，当任务执行之前开始调用此方法，可以在这里显示进度对话框。 onCancelled(): 用户调用取消时，要做的操作 使用AsyncTask类注意点 Task的实例必须在UI thread中创建； execute方法必须在UI thread中调用； 不要手动的调用onPreExecute(), onPostExecute(Result)，doInBackground(Params…), onProgressUpdate(Progress…)这几个方法； 该task只能被执行一次，多次调用时将会出现异常.","categories":[{"name":"Android","slug":"Android","permalink":"http://j2go.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://j2go.github.io/tags/Android/"}]},{"title":"Android 之 Intent 学习","slug":"2015-03-02-android-intent","date":"2015-03-01T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2015/03/01/2015-03-02-android-intent/","link":"","permalink":"http://j2go.github.io/2015/03/01/2015-03-02-android-intent/","excerpt":"","text":"Activity切换 两种方式 直接跳转12Intent intent = new Intent(MainActivity.this,SecondActivity.class);startActivity(intent); 需要携带参数则需使用1intent.putExtra(&quot;key&quot;, &quot;value&quot;); 目标Activity取参数使用1getIntent().getStringExtra(&quot;key&quot;) 带返回值跳转123Intent intent = new Intent(MainActivity.this,SecondActivity.class);intent.putExtra(\"key\", \"value\");startActivityForResult(intent, 1); 目标activity返回1234Intent intent = new Intent();intent.putExtra(\"code\", \"OK\");setResult((int)requestCode,intent); finish(); finish()函数 : 执行结束销毁此activity，这个ActivityResult返回回到调用者那里并调用onActivityResult()函数. 原activity接受返回值的操作123456789@Overrideprotected void onActivityResult(int requestCode, int resultCode, Intent data) &#123; super.onActivityResult(requestCode, resultCode, data); //判断操作 if (requestCode==1 &amp;&amp; resultCode==2) &#123; mEditText.setText(data.getStringExtra(\"code\")); //Toast.makeText(MainActivity.this, data.getStringExtra(\"code\"), Toast.LENGTH_LONG).show(); &#125;&#125;","categories":[{"name":"Android","slug":"Android","permalink":"http://j2go.github.io/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://j2go.github.io/tags/Android/"}]},{"title":"Hadoop环境配置遇到的问题","slug":"2015-01-29-hadoop-environment","date":"2015-01-28T16:00:00.000Z","updated":"2021-09-05T08:35:11.973Z","comments":true,"path":"2015/01/28/2015-01-29-hadoop-environment/","link":"","permalink":"http://j2go.github.io/2015/01/28/2015-01-29-hadoop-environment/","excerpt":"","text":"千不该万不该，换个题目跳个大坑，hadoop 没两把刷子还真玩不动。 Hadoop环境配置遇到的问题环境 系统：Windows7VM虚拟机：ubuntu14.04 i386jdk : jdk1.7.0_71 参考链接： http://www.cnblogs.com/kinglau/p/3794433.htmlhttp://www.cnblogs.com/kinglau/p/3796164.html http://blog.sina.com.cn/s/blog_675e4f240102uwim.htmlhttp://blog.sina.com.cn/s/blog_675e4f240102uwpe.html 遇到的问题及解决办法：单机配置时设置默认root密码root密码找回:1$sudo passwd root 输入你安装时用户的密码，设置root密码。 安装jdk时配置了环境还要替换一下系统的环境才能使用 jps 命令 将系统默认的jdk修改过来1234sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_05/bin/java 300sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_05/bin/javac 300sudo update-alternatives --config java sudo update-alternatives --config javac 新建的hadoop用户，需要解除 /usr/local/hadoop 目录权限限制1sudo chmod a+rwx /usr/local/hadoop 以下操作需要在hadoop用户下使用（不知道为什么）执行启动命令：12sbin/start-dfs.sh sbin/start-yarn.sh namenode没有启动12Cannot create directory /usr/hadoop/tmp/hdfs/name/current解决方案:hadoop@ubuntu:/usr/local/hadoop$ sudo chown -R hadoop:hadoop hdfs 再执行格式化:1234bin/hfds namenode -formathadoop@ubuntu:/usr/local/hadoop$ ls hdfs/namecurrenthadoop@ubuntu:/usr/local/hadoop$ sbin/start-all.sh 配置集群时在验证前，需要做两件事儿。第一件事是修改文件”authorized_keys”权限（权限的设置非常重要，因为不安全的设置，会让你不能使用 ssh 功能），另一件事儿是用root用户设置”/etc/ssh/sshd_config”的内容,使机器间可以无密码登陆访问。 修改文件”authorized_keys”1chmod 600 ~/.ssh/authorized_keys","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://j2go.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://j2go.github.io/tags/hadoop/"}]}]}